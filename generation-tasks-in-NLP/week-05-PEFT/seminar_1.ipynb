{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae02e77-f9a8-4326-8f9d-6c8621993faa",
   "metadata": {},
   "source": [
    "# Семинар 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ae023-6212-4693-bd7d-a075127fdfe2",
   "metadata": {},
   "source": [
    "В рамках сегодняшнего семинара мы с вами посмотрим на различные методы Parameter Efficient Fine-Tuning`а, релизуем некоторые на чистом pytorch, а также посмотрим на удобную бублиотеку peft от huggingface, которая позвволяет буквально в одну строчку интегрировать множесто PEFT методов вашу модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb7f54-dbff-4a2e-adfb-93c18f66ee4c",
   "metadata": {},
   "source": [
    "Начнем с самого часто используемого peft-метода - [LoRA](https://arxiv.org/abs/2106.09685)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c881e-0f3c-4846-8df2-2199d7ef0ced",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e044de-186f-4a1b-8cbd-7a7f07f70909",
   "metadata": {},
   "source": [
    "LoRA является одной из наиболее широко используемых и эффективных техник для эффективного обучения LLM. Это очень важная метод, который используется сейчас повсеместно, поэтому мы разберем его подробно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dac66-4c53-4639-9403-d51e57e01d40",
   "metadata": {},
   "source": [
    "Поскольку большие языковые модели тяжелые, обновление всех весов модели во время обучения может быть дорогостоящим из-за ограничений памяти GPU. Предположим, у нас есть большая матрица весов W для данного слоя. Во время обратного распространения ошибки мы учимся матрице ΔW, которая содержит информацию о том, насколько мы хотим обновить исходные веса, чтобы минимизировать функцию потерь во время обучения.\n",
    "\n",
    "В обычном режиме обучения обновление весов определяется следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7a9e5-4d9d-45b8-9813-4432af37e533",
   "metadata": {},
   "source": [
    "$$W_{updated}=W+\\Delta W$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223e62d-0fcb-49e4-9d32-5b163670ea81",
   "metadata": {},
   "source": [
    "LoRA предлагает более эффективную альтернативу вычислению обновлений весов ΔW за счет обучения их приближенного представления в виде произведения двух **низкоранговых** матриц А и В, ΔW ≈ AB:\n",
    "\n",
    "$$W_{updated}=W+A*B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f9e34-c4c3-48b4-88db-72f22a418138",
   "metadata": {},
   "source": [
    "![](./images/lora_1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91acd4-91f2-49d4-b3bb-82b78d1acdcd",
   "metadata": {},
   "source": [
    "Как LoRA экономит память GPU?   \n",
    "Если предобученная матрица весов W является матрицей размером 1,000×1,000, то матрица обновления весов ΔW при обычном fine-tune также будет матрицей 1,000×1,000. В этом случае ΔW имеет 1,000,000 параметров.  \n",
    "Если мы рассмотрим LoRA ранга 2, то A будет матрицей 1000×2, а B - матрицей 2×1000, и нам нужно обновить только 2×2×1,000 = 4,000 параметров при использовании LoRA. В предыдущем примере, с рангом 2, это **в 250 раз меньше параметров**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eea3ee-fde8-414c-bab3-0589c6df5525",
   "metadata": {},
   "source": [
    "Конечно, A и B не могут отражать всю информацию, которую есть в ΔW, но это сделано намеренно. Используя LoRA, мы предполагаем, что модели требуется, чтобы W была большой матрицей полного ранга, чтобы инкапсулировать все знание, накопленное в результате предобучения модели.  \n",
    "Однако во время fine-tun`а LLM, нам не нужно обновлять все веса и сильно менять накопленную информацию - достаточно приближенного обновления, которое достигается апроксимацией исходного обнолвения в более низкогоранговом предситавлении, которое мы формулируем через матрицы AB.\n",
    "\n",
    "Обратите внимание, что описанное выше немного расходится с тем, что изображено на рисунке выше. Это связано с распределительным законом умножения матриц: нам не нужно добавлять веса к обновляемым весами, но мы можем держать их отдельно. Например, если x - входные данные, тогда мы можем написать следующее для обычного fine-tuning`а:\n",
    "\n",
    "$$x.(W+\\Delta W)=x.W+x.\\Delta W$$\n",
    "\n",
    "или тоже самое для LoRA:\n",
    "\n",
    "$$x.(W+A*B)=x.W+x*A*B$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab7994-3861-4478-9ee2-e6a9f2fb40d7",
   "metadata": {},
   "source": [
    "Тот факт, что мы можем держать матрицы весов LoRA отдельно, делает LoRA особенно привлекательным. На практике это означает, что нам вообще не нужно изменять веса предобученной модели, так как мы можем применять матрицы LoRA на этапе inference. Это особенно полезно, если вы рассматриваете возможность хостинга модели для нескольких клиентов. Вместо того, чтобы сохранять большие обновленные модели для каждого клиента, вам нужно сохранить только небольшой набор весов LoRA вместе с оригинальной предобученной моделью.\n",
    "\n",
    "Простая реализация этого механизма выглядит очень просто в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ee8250-2e93-467c-a4aa-c1675d0cc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # NVIDIA CUDA Deep Neural Network (cuDNN) is a GPU-accelerated library of primitives for deep neural networks\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = nn.Parameter(torch.randn(in_dim, rank) * std_dev)\n",
    "        self.B = nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a35a0-53f7-4f59-91c1-a727453a3ad4",
   "metadata": {},
   "source": [
    "Обратите внимание, что у LoRA есть два гиперпараметра - `rank` и `alpha`. `rank` является гиперпараметром, который контролирует внутреннее измерение матриц A и B. Другими словами, этот параметр контролирует количество дополнительных параметров, введенных LoRA, и является ключевым фактором в определении баланса между адаптируемостью модели и эффективностью параметров.\n",
    "\n",
    "Второй гиперпараметр, `alpha`, является масштабирующим гиперпараметром, применяемым к выходу низкогорангового представления матрицы. Он по сути контролирует степень, в которой допускается влияние выхода адаптированного слоя на оригинальный выход адаптируемого слоя. Это может рассматриваться как способ регулирования влияния адаптации низкого ранга на выход исходного слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33dd79d-d014-462a-94b5-0920f1fefab1",
   "metadata": {},
   "source": [
    "Чтобы заменить имеющийся слой на какой либо текущий необходимо просто добавить реализацию выше к готовому линейному слою"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5cde30f4-3edf-4ac6-a87a-f3cc7e9ce5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.linear=linear\n",
    "        self.lora=LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        ).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)+self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4a66e-0918-4ab1-92a0-9f0460f1f55a",
   "metadata": {},
   "source": [
    "Попробуем сравнить обучение полной модели, и с использование peft-методов.\n",
    "Возьмем готовый код из предыдущего семинара по обучению модели BERT и посмотрим на разницу в скорости обучения и качеству "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ec7ae2-3ef6-4c49-860c-57f6394a426e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/snv-ds/NLP_course/master/week2/train -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05cbe5d6-bbed-40f6-bbe9-fd57b2816efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from lightning import Fabric\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")\n",
    "\n",
    "def prepare_data():\n",
    "    train = pd.read_csv('train', sep='\\t', names=['id','target','temp1','temp2','comment'], index_col=0)\n",
    "    parse_labels = ['__label__NORMAL','__label__INSULT','__label__THREAT','__label__OBSCENITY']\n",
    "    \n",
    "    mask = train['comment'].isin(parse_labels) # to cope only with correct rows in data\n",
    "    \n",
    "    train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask]['comment']\n",
    "    train.loc[mask,'comment'] = np.nan\n",
    "    \n",
    "    for t in ['temp1','temp2']: # if comment have several labels of classes\n",
    "        mask = train[t].isin(parse_labels)\n",
    "        train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask][t]\n",
    "        train.loc[mask,t] = np.nan\n",
    "        train.loc[~train[t].isna(),'comment'] = train[~train[t].isna()][t]\n",
    "    \n",
    "    train[['оскорбление','другое','непростойность','угроза']] = train['target'].str.get_dummies(sep=',')\n",
    "    \n",
    "    train = train[['другое','оскорбление','непростойность','угроза', 'comment']]\n",
    "    return train\n",
    "\n",
    "def split_data_for_training(df, test_size=0.2):\n",
    "    train_text, val_text, train_labels, val_labels = train_test_split(df.comment,\n",
    "                                                                      df[['другое','оскорбление',\n",
    "                                                                         'непростойность','угроза']],\n",
    "                                                                      test_size = test_size,\n",
    "                                                                      random_state=2029)\n",
    "    return train_text, val_text, train_labels, val_labels\n",
    "\n",
    "def prepare_tokens(tokenizer, text, max_len=50):\n",
    "    tokens = tokenizer.batch_encode_plus(\n",
    "        text.tolist(),\n",
    "        max_length = max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    return tokens\n",
    "\n",
    "def init_data_loaders(text: pd.Series, labels: pd.Series, batch_size=32, tokenizer=tokenizer):\n",
    "    tokenized_text = prepare_tokens(tokenizer, text)\n",
    "    input_ids = torch.tensor(tokenized_text['input_ids'])\n",
    "    mask = torch.tensor(tokenized_text['attention_mask'])\n",
    "    labels = torch.tensor(labels.values.tolist(), dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(input_ids, mask, labels)\n",
    "    sampler = RandomSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e707bcd5-60ff-496a-a47b-31d18a30f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = dict(enumerate(['__label__NORMAL','__label__INSULT','__label__THREAT','__label__OBSCENITY']))\n",
    "label2id = {label: ind for ind, label in id2label.items()}\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_embeder = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased-conversational\", num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc39bd22-4916-4b75-8ed9-878bbd7774f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177856516  parameters in model\n"
     ]
    }
   ],
   "source": [
    "train_text, val_text, train_labels, val_labels = split_data_for_training(prepare_data())\n",
    "train_dataloader, val_dataloader = init_data_loaders(train_text, train_labels), init_data_loaders(val_text, val_labels)\n",
    "\n",
    "# model_embeder = BERT_Arch(model, n_output=4).to(device)\n",
    "print(sum(param.numel() for param in model_embeder.parameters()), \" parameters in model\")\n",
    "optimizer = AdamW(model_embeder.parameters(), lr = 1e-5)\n",
    "cross_entropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1057882-eed3-45fd-870d-02ce6eea1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_preds=[]\n",
    "  \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "    \n",
    "        model.zero_grad()        \n",
    "        preds = model(sent_id, mask).logits\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss = total_loss + loss.item()\n",
    "      \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    return (avg_loss, total_preds), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d107807-9e6a-40ec-9643-c993f666ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    print(\"\\nEvaluating...\")  \n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_preds, total_labels = [], []\n",
    "  \n",
    "    for step,batch in enumerate(tqdm(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask).logits\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "    \n",
    "            total_preds.append(preds.detach().cpu().numpy())\n",
    "            total_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    total_labels  = np.concatenate(total_labels, axis=0)\n",
    "  \n",
    "    print(classification_report(total_labels,\n",
    "                                torch.sigmoid(torch.tensor(total_preds)).round(),\n",
    "                                zero_division=True))\n",
    "\n",
    "    return (avg_loss, total_preds),  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6afac00-f558-4118-9044-fe8b79665207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c009ada20a49428a26723fe8c2994c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dc79846d8a4fd59fd9bd93171ef439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     24352\n",
      "           1       0.90      0.93      0.92      4458\n",
      "           2       0.81      0.81      0.81       470\n",
      "           3       0.80      0.92      0.86      1507\n",
      "\n",
      "   micro avg       0.96      0.97      0.97     30787\n",
      "   macro avg       0.88      0.91      0.89     30787\n",
      "weighted avg       0.97      0.97      0.97     30787\n",
      " samples avg       0.97      0.97      0.97     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.071\n",
      "Validation Loss: 0.054\n",
      "\n",
      " Epoch 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b5dca39a044eeaaed6f940d06e3601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe961fd870a4c8fab921294dc604090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24352\n",
      "           1       0.93      0.91      0.92      4458\n",
      "           2       0.87      0.77      0.81       470\n",
      "           3       0.87      0.92      0.89      1507\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     30787\n",
      "   macro avg       0.91      0.89      0.90     30787\n",
      "weighted avg       0.97      0.97      0.97     30787\n",
      " samples avg       0.97      0.97      0.97     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.036\n",
      "Validation Loss: 0.052\n",
      "\n",
      " Epoch 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99358093682347d9bd02004ef38310e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225c94aadd83467a85543f7a55112e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24352\n",
      "           1       0.91      0.92      0.92      4458\n",
      "           2       0.85      0.81      0.83       470\n",
      "           3       0.88      0.90      0.89      1507\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     30787\n",
      "   macro avg       0.91      0.91      0.91     30787\n",
      "weighted avg       0.97      0.97      0.97     30787\n",
      " samples avg       0.97      0.97      0.97     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.023\n",
      "Validation Loss: 0.057\n",
      "\n",
      " Epoch 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7fd41f9f0640aab4ebfa4ceba7dda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e934412bf45042cabb4cbbde3c21df95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24352\n",
      "           1       0.93      0.90      0.91      4458\n",
      "           2       0.80      0.88      0.84       470\n",
      "           3       0.88      0.88      0.88      1507\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     30787\n",
      "   macro avg       0.90      0.91      0.90     30787\n",
      "weighted avg       0.97      0.97      0.97     30787\n",
      " samples avg       0.97      0.97      0.97     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.014\n",
      "Validation Loss: 0.074\n",
      "\n",
      " Epoch 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd3ea14040447d087a2079b54b4e96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc86299cbb745a7b8a13536f765d055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     24352\n",
      "           1       0.91      0.92      0.91      4458\n",
      "           2       0.81      0.85      0.83       470\n",
      "           3       0.87      0.89      0.88      1507\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     30787\n",
      "   macro avg       0.89      0.91      0.90     30787\n",
      "weighted avg       0.97      0.97      0.97     30787\n",
      " samples avg       0.97      0.97      0.97     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.010\n",
      "Validation Loss: 0.092\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    (train_loss, _), model_embeder = train(model_embeder)\n",
    "    (valid_loss, _), model_embeder = evaluate(model_embeder)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_embeder.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e2791-4207-4153-b724-8c85d890b2e5",
   "metadata": {},
   "source": [
    "Как выидите  получилось отличное качество модели, но при этом мы обучали все 177М параметров модели. Попробуем альтернативные варианты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35641214-03a8-41d4-8481-bc49995b005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177856516 trainable parameters in model\n"
     ]
    }
   ],
   "source": [
    "print(sum(param.numel() for param in model_embeder.parameters() if param.requires_grad), \"trainable parameters in model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "52e10d70-d4c1-4c37-b025-61da6b2b29e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "model_embeder = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased-conversational\", num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "lora_model_embeder = deepcopy(model_embeder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5e848-98ce-43f2-8cc6-a175d70d00f9",
   "metadata": {},
   "source": [
    "Заморозим веса исходной модели, и попробуем обучить теперь LoRA-адаптеры для нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a713a737-4b07-4a32-9b9b-385102a536fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3076 trainable parameters in model\n"
     ]
    }
   ],
   "source": [
    "for param in lora_model_embeder.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "print(sum(param.numel() for param in lora_model_embeder.parameters() if param.requires_grad), \"trainable parameters in model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "16f3a73a-aaca-488c-92cf-a4a9e7beb155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight: False\n",
      "embeddings.position_embeddings.weight: False\n",
      "embeddings.token_type_embeddings.weight: False\n",
      "embeddings.LayerNorm.weight: False\n",
      "embeddings.LayerNorm.bias: False\n",
      "encoder.layer.0.attention.self.query.weight: False\n",
      "encoder.layer.0.attention.self.query.bias: False\n",
      "encoder.layer.0.attention.self.key.weight: False\n",
      "encoder.layer.0.attention.self.key.bias: False\n",
      "encoder.layer.0.attention.self.value.weight: False\n",
      "encoder.layer.0.attention.self.value.bias: False\n",
      "encoder.layer.0.attention.output.dense.weight: False\n",
      "encoder.layer.0.attention.output.dense.bias: False\n",
      "encoder.layer.0.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.0.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.0.intermediate.dense.weight: False\n",
      "encoder.layer.0.intermediate.dense.bias: False\n",
      "encoder.layer.0.output.dense.weight: False\n",
      "encoder.layer.0.output.dense.bias: False\n",
      "encoder.layer.0.output.LayerNorm.weight: False\n",
      "encoder.layer.0.output.LayerNorm.bias: False\n",
      "encoder.layer.1.attention.self.query.weight: False\n",
      "encoder.layer.1.attention.self.query.bias: False\n",
      "encoder.layer.1.attention.self.key.weight: False\n",
      "encoder.layer.1.attention.self.key.bias: False\n",
      "encoder.layer.1.attention.self.value.weight: False\n",
      "encoder.layer.1.attention.self.value.bias: False\n",
      "encoder.layer.1.attention.output.dense.weight: False\n",
      "encoder.layer.1.attention.output.dense.bias: False\n",
      "encoder.layer.1.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.1.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.1.intermediate.dense.weight: False\n",
      "encoder.layer.1.intermediate.dense.bias: False\n",
      "encoder.layer.1.output.dense.weight: False\n",
      "encoder.layer.1.output.dense.bias: False\n",
      "encoder.layer.1.output.LayerNorm.weight: False\n",
      "encoder.layer.1.output.LayerNorm.bias: False\n",
      "encoder.layer.2.attention.self.query.weight: False\n",
      "encoder.layer.2.attention.self.query.bias: False\n",
      "encoder.layer.2.attention.self.key.weight: False\n",
      "encoder.layer.2.attention.self.key.bias: False\n",
      "encoder.layer.2.attention.self.value.weight: False\n",
      "encoder.layer.2.attention.self.value.bias: False\n",
      "encoder.layer.2.attention.output.dense.weight: False\n",
      "encoder.layer.2.attention.output.dense.bias: False\n",
      "encoder.layer.2.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.2.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.2.intermediate.dense.weight: False\n",
      "encoder.layer.2.intermediate.dense.bias: False\n",
      "encoder.layer.2.output.dense.weight: False\n",
      "encoder.layer.2.output.dense.bias: False\n",
      "encoder.layer.2.output.LayerNorm.weight: False\n",
      "encoder.layer.2.output.LayerNorm.bias: False\n",
      "encoder.layer.3.attention.self.query.weight: False\n",
      "encoder.layer.3.attention.self.query.bias: False\n",
      "encoder.layer.3.attention.self.key.weight: False\n",
      "encoder.layer.3.attention.self.key.bias: False\n",
      "encoder.layer.3.attention.self.value.weight: False\n",
      "encoder.layer.3.attention.self.value.bias: False\n",
      "encoder.layer.3.attention.output.dense.weight: False\n",
      "encoder.layer.3.attention.output.dense.bias: False\n",
      "encoder.layer.3.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.3.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.3.intermediate.dense.weight: False\n",
      "encoder.layer.3.intermediate.dense.bias: False\n",
      "encoder.layer.3.output.dense.weight: False\n",
      "encoder.layer.3.output.dense.bias: False\n",
      "encoder.layer.3.output.LayerNorm.weight: False\n",
      "encoder.layer.3.output.LayerNorm.bias: False\n",
      "encoder.layer.4.attention.self.query.weight: False\n",
      "encoder.layer.4.attention.self.query.bias: False\n",
      "encoder.layer.4.attention.self.key.weight: False\n",
      "encoder.layer.4.attention.self.key.bias: False\n",
      "encoder.layer.4.attention.self.value.weight: False\n",
      "encoder.layer.4.attention.self.value.bias: False\n",
      "encoder.layer.4.attention.output.dense.weight: False\n",
      "encoder.layer.4.attention.output.dense.bias: False\n",
      "encoder.layer.4.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.4.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.4.intermediate.dense.weight: False\n",
      "encoder.layer.4.intermediate.dense.bias: False\n",
      "encoder.layer.4.output.dense.weight: False\n",
      "encoder.layer.4.output.dense.bias: False\n",
      "encoder.layer.4.output.LayerNorm.weight: False\n",
      "encoder.layer.4.output.LayerNorm.bias: False\n",
      "encoder.layer.5.attention.self.query.weight: False\n",
      "encoder.layer.5.attention.self.query.bias: False\n",
      "encoder.layer.5.attention.self.key.weight: False\n",
      "encoder.layer.5.attention.self.key.bias: False\n",
      "encoder.layer.5.attention.self.value.weight: False\n",
      "encoder.layer.5.attention.self.value.bias: False\n",
      "encoder.layer.5.attention.output.dense.weight: False\n",
      "encoder.layer.5.attention.output.dense.bias: False\n",
      "encoder.layer.5.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.5.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.5.intermediate.dense.weight: False\n",
      "encoder.layer.5.intermediate.dense.bias: False\n",
      "encoder.layer.5.output.dense.weight: False\n",
      "encoder.layer.5.output.dense.bias: False\n",
      "encoder.layer.5.output.LayerNorm.weight: False\n",
      "encoder.layer.5.output.LayerNorm.bias: False\n",
      "encoder.layer.6.attention.self.query.weight: False\n",
      "encoder.layer.6.attention.self.query.bias: False\n",
      "encoder.layer.6.attention.self.key.weight: False\n",
      "encoder.layer.6.attention.self.key.bias: False\n",
      "encoder.layer.6.attention.self.value.weight: False\n",
      "encoder.layer.6.attention.self.value.bias: False\n",
      "encoder.layer.6.attention.output.dense.weight: False\n",
      "encoder.layer.6.attention.output.dense.bias: False\n",
      "encoder.layer.6.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.6.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.6.intermediate.dense.weight: False\n",
      "encoder.layer.6.intermediate.dense.bias: False\n",
      "encoder.layer.6.output.dense.weight: False\n",
      "encoder.layer.6.output.dense.bias: False\n",
      "encoder.layer.6.output.LayerNorm.weight: False\n",
      "encoder.layer.6.output.LayerNorm.bias: False\n",
      "encoder.layer.7.attention.self.query.weight: False\n",
      "encoder.layer.7.attention.self.query.bias: False\n",
      "encoder.layer.7.attention.self.key.weight: False\n",
      "encoder.layer.7.attention.self.key.bias: False\n",
      "encoder.layer.7.attention.self.value.weight: False\n",
      "encoder.layer.7.attention.self.value.bias: False\n",
      "encoder.layer.7.attention.output.dense.weight: False\n",
      "encoder.layer.7.attention.output.dense.bias: False\n",
      "encoder.layer.7.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.7.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.7.intermediate.dense.weight: False\n",
      "encoder.layer.7.intermediate.dense.bias: False\n",
      "encoder.layer.7.output.dense.weight: False\n",
      "encoder.layer.7.output.dense.bias: False\n",
      "encoder.layer.7.output.LayerNorm.weight: False\n",
      "encoder.layer.7.output.LayerNorm.bias: False\n",
      "encoder.layer.8.attention.self.query.weight: False\n",
      "encoder.layer.8.attention.self.query.bias: False\n",
      "encoder.layer.8.attention.self.key.weight: False\n",
      "encoder.layer.8.attention.self.key.bias: False\n",
      "encoder.layer.8.attention.self.value.weight: False\n",
      "encoder.layer.8.attention.self.value.bias: False\n",
      "encoder.layer.8.attention.output.dense.weight: False\n",
      "encoder.layer.8.attention.output.dense.bias: False\n",
      "encoder.layer.8.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.8.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.8.intermediate.dense.weight: False\n",
      "encoder.layer.8.intermediate.dense.bias: False\n",
      "encoder.layer.8.output.dense.weight: False\n",
      "encoder.layer.8.output.dense.bias: False\n",
      "encoder.layer.8.output.LayerNorm.weight: False\n",
      "encoder.layer.8.output.LayerNorm.bias: False\n",
      "encoder.layer.9.attention.self.query.weight: False\n",
      "encoder.layer.9.attention.self.query.bias: False\n",
      "encoder.layer.9.attention.self.key.weight: False\n",
      "encoder.layer.9.attention.self.key.bias: False\n",
      "encoder.layer.9.attention.self.value.weight: False\n",
      "encoder.layer.9.attention.self.value.bias: False\n",
      "encoder.layer.9.attention.output.dense.weight: False\n",
      "encoder.layer.9.attention.output.dense.bias: False\n",
      "encoder.layer.9.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.9.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.9.intermediate.dense.weight: False\n",
      "encoder.layer.9.intermediate.dense.bias: False\n",
      "encoder.layer.9.output.dense.weight: False\n",
      "encoder.layer.9.output.dense.bias: False\n",
      "encoder.layer.9.output.LayerNorm.weight: False\n",
      "encoder.layer.9.output.LayerNorm.bias: False\n",
      "encoder.layer.10.attention.self.query.weight: False\n",
      "encoder.layer.10.attention.self.query.bias: False\n",
      "encoder.layer.10.attention.self.key.weight: False\n",
      "encoder.layer.10.attention.self.key.bias: False\n",
      "encoder.layer.10.attention.self.value.weight: False\n",
      "encoder.layer.10.attention.self.value.bias: False\n",
      "encoder.layer.10.attention.output.dense.weight: False\n",
      "encoder.layer.10.attention.output.dense.bias: False\n",
      "encoder.layer.10.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.10.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.10.intermediate.dense.weight: False\n",
      "encoder.layer.10.intermediate.dense.bias: False\n",
      "encoder.layer.10.output.dense.weight: False\n",
      "encoder.layer.10.output.dense.bias: False\n",
      "encoder.layer.10.output.LayerNorm.weight: False\n",
      "encoder.layer.10.output.LayerNorm.bias: False\n",
      "encoder.layer.11.attention.self.query.weight: False\n",
      "encoder.layer.11.attention.self.query.bias: False\n",
      "encoder.layer.11.attention.self.key.weight: False\n",
      "encoder.layer.11.attention.self.key.bias: False\n",
      "encoder.layer.11.attention.self.value.weight: False\n",
      "encoder.layer.11.attention.self.value.bias: False\n",
      "encoder.layer.11.attention.output.dense.weight: False\n",
      "encoder.layer.11.attention.output.dense.bias: False\n",
      "encoder.layer.11.attention.output.LayerNorm.weight: False\n",
      "encoder.layer.11.attention.output.LayerNorm.bias: False\n",
      "encoder.layer.11.intermediate.dense.weight: False\n",
      "encoder.layer.11.intermediate.dense.bias: False\n",
      "encoder.layer.11.output.dense.weight: False\n",
      "encoder.layer.11.output.dense.bias: False\n",
      "encoder.layer.11.output.LayerNorm.weight: False\n",
      "encoder.layer.11.output.LayerNorm.bias: False\n",
      "pooler.dense.weight: False\n",
      "pooler.dense.bias: False\n"
     ]
    }
   ],
   "source": [
    "for name, param in lora_model_embeder.bert.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877d693-2529-4d08-9832-4c0874f32cb4",
   "metadata": {},
   "source": [
    "Оригинальная статья адаптирует только веса слоя attention в Transformer с помощью LoRA. adapter-transformers дополнительно позволяет вводить LoRA в FFN слои блока Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6a8d8-7152-4605-ba89-5513a01000da",
   "metadata": {},
   "source": [
    "добавим LoRA в каждый слой attention`а. Самостоятельно вы можете попробовать и другие слои для добавления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "85268613-5f24-474e-a533-ca1914f17d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592900 trainable parameters in model\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):  # N of layers in BERT\n",
    "        lora_model_embeder.bert.encoder.layer[i].attention.self.query = LinearWithLoRA(\n",
    "            lora_model_embeder.bert.encoder.layer[i].attention.self.query, 8, 32\n",
    "        )\n",
    "        lora_model_embeder.bert.encoder.layer[i].attention.self.key = LinearWithLoRA(\n",
    "            lora_model_embeder.bert.encoder.layer[i].attention.self.key, 8, 32\n",
    "        )\n",
    "        lora_model_embeder.bert.encoder.layer[i].attention.self.value = LinearWithLoRA(\n",
    "            lora_model_embeder.bert.encoder.layer[i].attention.self.value, 8, 32\n",
    "        )\n",
    "        lora_model_embeder.bert.encoder.layer[i].attention.output.dense = LinearWithLoRA(\n",
    "            lora_model_embeder.bert.encoder.layer[i].attention.output.dense, 8, 32\n",
    "        )\n",
    "print(sum(param.numel() for param in lora_model_embeder.parameters() if param.requires_grad), \"trainable parameters in model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962a620-ae13-4c70-8f34-33e7c371f4eb",
   "metadata": {},
   "source": [
    "Получили всего около 600К обучаемых параметров, что заметно меньше исходного количества для полного FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "39ffe4f7-c600-4e22-9b8d-e36b657921a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333% of total amount of parameters\n"
     ]
    }
   ],
   "source": [
    "total_param_number = sum(param.numel() for param in model_embeder.parameters())\n",
    "n_lora_trainable_params = sum(param.numel() for param in lora_model_embeder.parameters() if param.requires_grad)\n",
    "print(f\"{round((n_lora_trainable_params / 177856516) * 100, 3)}% of total amount of parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4f7979bb-5663-49c1-a7c6-42b96c103540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4148cb8358eb441fad68c1296d3a65db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897fd7ca66d84f3585b074e5e8513a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     24352\n",
      "           1       0.87      0.91      0.89      4458\n",
      "           2       0.60      0.67      0.64       470\n",
      "           3       0.84      0.82      0.83      1507\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     30787\n",
      "   macro avg       0.82      0.84      0.83     30787\n",
      "weighted avg       0.96      0.95      0.95     30787\n",
      " samples avg       0.96      0.96      0.96     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.133\n",
      "Validation Loss: 0.074\n",
      "\n",
      " Epoch 2 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a82006ccaa844559243a255ee81ef40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f778500cc954b70b33adf236c8b17a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     24352\n",
      "           1       0.89      0.88      0.88      4458\n",
      "           2       0.70      0.77      0.73       470\n",
      "           3       0.81      0.83      0.82      1507\n",
      "\n",
      "   micro avg       0.96      0.95      0.95     30787\n",
      "   macro avg       0.84      0.86      0.85     30787\n",
      "weighted avg       0.96      0.95      0.95     30787\n",
      " samples avg       0.96      0.96      0.96     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.083\n",
      "Validation Loss: 0.068\n",
      "\n",
      " Epoch 3 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dda3564c3f940db8243abc68b64691b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ffd11b3d2c4b4fa22eb13a858337e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     24352\n",
      "           1       0.81      0.94      0.87      4458\n",
      "           2       0.60      0.79      0.68       470\n",
      "           3       0.86      0.77      0.81      1507\n",
      "\n",
      "   micro avg       0.94      0.95      0.95     30787\n",
      "   macro avg       0.81      0.87      0.83     30787\n",
      "weighted avg       0.95      0.95      0.95     30787\n",
      " samples avg       0.95      0.95      0.95     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.082\n",
      "Validation Loss: 0.080\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "optimizer = AdamW(lora_model_embeder.parameters(), lr = 1e-5)\n",
    "cross_entropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "epochs = 3\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    (train_loss, _), model_embeder = train(lora_model_embeder)\n",
    "    (valid_loss, _), model_embeder = evaluate(lora_model_embeder)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lora_model_embeder.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d0ce6-8127-4beb-9cf8-9201fa7d45ee",
   "metadata": {},
   "source": [
    "Как видите, этот метод достигает практически аналогичных значений качества при этом обучая всего 0.33% параметров модели, при этом затрачивая почти вдвое меньше времени"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca246eb8-d649-4c15-831f-07991bdc2f3f",
   "metadata": {},
   "source": [
    "## IA3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dd8c5e-81e4-4feb-a8b2-2f74ef78105a",
   "metadata": {},
   "source": [
    "Чтобы сделать Fine-tuning еще эффективнее, метод [IA^3](https://arxiv.org/pdf/2205.05638.pdf) (Infused Adapter by Inhibiting and Amplifying Inner Activations) масштабирует внутренние активации с помощью изученных векторов. Эти обучаемые вектора вводятся в модули attention и feedforward блоки в типовой трансформерной архитектуре. Эти обучаемые вектора являются единственными обучаемыми параметрами во время Fine-tuning`а, и таким образом оригинальные веса остаются замороженными. Обучая только эти вектора (в отличие от матриц в LoRA) еще больше уменьшает общее количество обучаемых параметров, что позволяет потенциально еще эффективнее обучать модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed9931-4eff-49b8-bba7-bf3d077abc86",
   "metadata": {},
   "source": [
    "![](./images/IA\\*\\*3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2ddf4-9af6-4bc8-a36c-8405603bcf95",
   "metadata": {},
   "source": [
    "(IA)^3 вводит обучаемые векторы $l_{W}$ в различные компоненты модели Transformer, которые выполняют поэлементное масштабирование внутренних активаций модели. Таким образом, для любого слоя модели, выраженного как матричное умножение вида h=Wx, он выполняет поэлементное умножение с $l_{W}$, токое что:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54338d3-2512-4440-8a6e-81249e6960aa",
   "metadata": {},
   "source": [
    "$$h=l_{W}⊙Wx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86754113-11dc-4b88-bcda-937b465c3d8c",
   "metadata": {},
   "source": [
    "Пример псевдокода для данного метода выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9be11e-2624-4f42-a737-78afa6d13060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block_with_ia3(x):\n",
    "    residual = x\n",
    "    x = ia3_self_attention(x)\n",
    "    x = LN(x + residual)\n",
    "    residual =  x\n",
    "    x = x @ W_1  # FFN in\n",
    "    x = l_ff * gelu(x)  # (IA)**3 scaling\n",
    "    x = x @ W_2  # FFN out\n",
    "    x = LN(x + residual)\n",
    "    return x\n",
    "\n",
    "def ia3_self_attention(x):\n",
    "    k, q, v = x @ W_k, x @ W_q, x @ W_v\n",
    "    k = l_k * k\n",
    "    v = l_v * v\n",
    "    return softmax(q @ k.T) @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbf210-8d7d-405a-af8d-4b68752aa08a",
   "metadata": {},
   "source": [
    "Чтобы не переписывать практически целиком весь BERT и не мучаться с корректной инициализацией весов попробуем обучить этот метод в самом конце с использованием библиотеки peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afdc85c-97f9-4c6e-8728-9e0158d87874",
   "metadata": {},
   "source": [
    "Примерный код для блока attention с использованием peft-метода IA^3 может выглядеть примерно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad792b-17df-4ba0-9841-65ee9883c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IA3Attention(nn.Module):\n",
    "    def __init__(self, config: LLaMAConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.n_heads = config.n_heads\n",
    "        self.head_dim = config.dim // config.n_heads\n",
    "\n",
    "        self.q_proj = NoInitLinear(config.dim, config.dim, bias=False, dtype=config.dtype)\n",
    "        self.k_proj = NoInitLinear(config.dim, config.dim, bias=False, dtype=config.dtype)\n",
    "        self.v_proj = NoInitLinear(config.dim, config.dim, bias=False, dtype=config.dtype)\n",
    "        self.o_proj = NoInitLinear(config.dim, config.dim, bias=False, dtype=config.dtype)\n",
    "\n",
    "        # IA3-specific parameters:\n",
    "        self.peft_l_k = nn.Parameter(torch.ones(1, self.n_heads, 1, self.head_dim, dtype=config.dtype))\n",
    "        self.peft_l_v = nn.Parameter(torch.ones(1, self.n_heads, 1, self.head_dim, dtype=config.dtype))\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        batch_size, q_seq_len, hidden_dim = hidden_states.size()\n",
    "\n",
    "        # (batch_size, num_heads, q_seq_len, head_dim)\n",
    "        query_states = self.q_proj(hidden_states).view(\n",
    "            batch_size, q_seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = self.k_proj(hidden_states).view(\n",
    "            batch_size, q_seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = self.v_proj(hidden_states).view(\n",
    "            batch_size, q_seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # IA3-specific:\n",
    "        query_states = query_states * self.peft_l_k\n",
    "        value_states = value_states * self.peft_l_v\n",
    "        # end of IA3-specific\n",
    "\n",
    "        scores = torch.matmul(\n",
    "            query_states, key_states.transpose(3, 2).type_as(query_states) / math.sqrt(self.head_dim)\n",
    "        )\n",
    "        scores += attention_mask\n",
    "\n",
    "        # (batch_size, num_heads, q_seq_len, kv_seq_len)\n",
    "        attn_weights = F.softmax(scores.float(), dim=-1).type_as(scores)\n",
    "        # (batch_size, num_heads, q_seq_len, head_dim)\n",
    "        attn_output = torch.matmul(attn_weights, value_states.type_as(query_states))\n",
    "        # (batch_size, q_seq_len, hidden_dim)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, q_seq_len, hidden_dim,\n",
    "        )\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "        check_nan(attn_output)\n",
    "        return {\"attn_output\": attn_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f8e95-d4cf-4ced-9cd4-5bfd8e04ce30",
   "metadata": {},
   "source": [
    "## Библиотека PEFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfb888-227b-4ec1-ae3a-c4486cd6849b",
   "metadata": {},
   "source": [
    "PEFT (Parameter-Efficient Fine-Tuning) — это библиотека для эффективной тренировки больших предобученных моделей на различные прикладные задачи без необходимости обучения всех параметров модели, поскольку это чрезвычайно дорого. PEFT методы позволяют обучать лишь небольшое количество (дополнительных) параметров модели — значительно снижая вычислительные затраты и занимаемое место на диске — при этом он обеспечивают сопоставимую с полным fine-tunингом модели производительность. Это делает более доступным обучение и хранение больших языковых моделей (LLM) на потребительском оборудовании.\n",
    "\n",
    "PEFT интегрирован с библиотеками Transformers, Diffusers и Accelerate для обеспечения более быстрого и удобного способа загрузки, обучения и использования больших моделей для вывода.\n",
    "\n",
    "Давайте посмотрим как очень просто можно применить адаптеры к нашей предобученной модели ruConversationalBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eba8e4-15a8-411f-a821-9c2ee01671f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, IA3Config,  TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.self.query\", \"attention.self.key\", \"attention.self.value\",\"attention.output.dense\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased-conversational\", num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "print(sum(param.numel() for param in peft_model.parameters() if param.requires_grad), \"trainable parameters in model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d6812-96e7-4823-9d68-3d74b91b31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725a7d3-0f89-418e-9ad9-8192400208dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr = 1e-5)\n",
    "cross_entropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "epochs = 3\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    (train_loss, _), model_embeder = train(peft_model)\n",
    "    (valid_loss, _), model_embeder = evaluate(peft_model)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(peft_model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b1e4f-49ed-4fc2-996c-cdd8db743086",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим, как можно обучить модель с использоаванием метода IA^3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88adf173-0871-4e24-bcd7-37e6678068cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia3_config = IA3Config(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"attention.self.query\", \"attention.self.key\", \"attention.self.value\", \"intermediate.dense\", \"output.dense\"],\n",
    "    feedforward_modules=[\"intermediate.dense\", \"output.dense\"]\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased-conversational\", num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "peft_model = get_peft_model(model, ia3_config)\n",
    "print(sum(param.numel() for param in peft_model.parameters() if param.requires_grad), \"trainable parameters in model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26415de5-e785-436c-a689-6e804e7fab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr = 1e-5)\n",
    "cross_entropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "epochs = 3\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "`\n",
    "    (train_loss, _), model_embeder = train(peft_model)\n",
    "    (valid_loss, _), model_embeder = evaluate(peft_model)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(peft_model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ad911-2dce-4113-af0d-6ae0160e9ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f2c49-330f-4f78-83bf-4ac62a5c4034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25e8c19-f8d1-42ca-a934-962578a70788",
   "metadata": {},
   "source": [
    "## Prefix-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088b61a-cdf6-4a78-bd95-f5f04c0832b4",
   "metadata": {},
   "source": [
    "[Prefix Tuning](https://arxiv.org/pdf/2101.00190.pdf) вводит новые параметры в блоки Multi-Head Attention каждого слоя Transformer. В иллюстрации ниже префиксы отмечены розовым и фиолетовым цветами. Более конкретно, мы добавляем обучаемые векторы префиксов PK и PV к ключам и значениям входа головы внимания, каждый с конфигурируемой длиной префикса l (атрибут prefix_length):\n",
    "\n",
    "$$\n",
    "\\text{head}_i = \\text{Attention}(QW_{i}^{Q}, [PK_{i}^{K}, WK_{i}^{K}], [PV_i^{V}, VW^{V}_{i}])\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd8d38-545d-408f-813a-df3f9051736c",
   "metadata": {},
   "source": [
    "![](./images/prefix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09230047-4b7e-4bcb-9bd8-6ee8d97aa6c4",
   "metadata": {},
   "source": [
    "Если коротко сформулировать принцип работы prefix-tuning`а, то мы делаем fine-tuning только части нашего входа модели - soft-prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532b22c-bbb5-47f6-aea0-e9339362f5cb",
   "metadata": {},
   "source": [
    "в псевдокоде этот методе может выглядеть примерно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4eec39-446e-4afb-acc7-b87276bbd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_tuning_attention(input_ids):\n",
    "    q = x @ W_q\n",
    "    k = cat([s_k, x]) @ W_k  # prepending  soft-promt, that will be trained \n",
    "    v = cat([s_v, x]) @ W_v  # prepending  soft-promt, that will be trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3b340-b173-4fc8-ab0d-83baf72a4dfa",
   "metadata": {},
   "source": [
    "Обучаясь всего на 0,1% параметров, Prefix-tuning показывает сопоставимую производительность в условиях полного объема данных, превосходит FT в условиях недостатка данных и лучше экстраполируется на примеры с темами, не встречавшимися во время обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b214b-755b-4e69-af26-4e9a339d36fe",
   "metadata": {},
   "source": [
    "Рассмотрим библиотеку для работы с prefix-tunig`ом от коллег из SberDevices под названием ruprompts. Она заточена под использование с немного устаревшей моделью rugpt-3, однако для быстрого прототипирования иногда может быть полезна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb0e55-f3a5-49da-90c8-71a138747c6e",
   "metadata": {},
   "source": [
    "Общая идея следующая: поскольку все слова, а точнее токены, переводятся в эмбеддинги (векторы фиксированной размерности), то эмбеддинги, соответствующие затравке, можно напрямую обучить градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d455e-7686-4d71-a30b-fcafa8a437c3",
   "metadata": {},
   "source": [
    "Обучаемая затравка (trainable prompt) логично разбивается на два компонента: формат (prompt format) и провайдер (prompt provider). Поясним на примере. Допустим, мы хотим обучить нейросеть отвечать на вопрос после прочтения текста. В случае, если мы решаем задачу методом zero-shot, формат затравки, скорее всего, будет примерно таким:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bed73-076a-448d-8f94-5896b516cd8d",
   "metadata": {},
   "source": [
    "```\n",
    "Текст:\n",
    "{passage}\n",
    "\n",
    "Вопрос: {question}\n",
    "Ответ:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30acbec-3a1a-4b16-be97-39a3b88ba1a5",
   "metadata": {},
   "source": [
    "Например, этот обучающий пример:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"passage\": \"GPT-3 устроена следующим образом: [...]\",\n",
    "    \"question\": \"Как устроен self-attention?\"\n",
    "}\n",
    "```\n",
    "\n",
    "будет отформатирован и подан в модель в следующем виде:\n",
    "\n",
    "\n",
    "```\n",
    "Текст:\n",
    "GPT-3 устроена следующим образом: [...]\n",
    "\n",
    "Вопрос: Как устроен self-attention?\n",
    "Ответ:\n",
    "```\n",
    "\n",
    "Сгенерированные моделью следующие токены мы и будем считать ответом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fccc34-7d4d-46bb-9422-fec6c19c2e00",
   "metadata": {},
   "source": [
    "Если же мы не уверены в том, что текстовые инструкции `(Текст:\\n, \\nВопрос:, \\nОтвет:)` достаточно хорошо подходят к задаче, то prompt tuning позволяет нам заменить их на обучаемые токены (`<P>`) и контролировать только их количество. Таким образом, формат затравки примет следующий вид:\n",
    "\n",
    "```\n",
    "<P><P><P><P>{passage}<P><P><P><P>{question}<P><P><P><P>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba45f2-33bd-43c6-8db0-a13f35f04e5e",
   "metadata": {},
   "source": [
    "При переводе токенов в эмбеддинги вместо словарных токенов подставляются их обычные эмбеддинги, а вместо обучаемых токенов (`<P>`) последовательно подставляются дифференцируемые эмбеддинги из провайдера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bbdc0-aeac-4ecf-9c48-ac5f474887b8",
   "metadata": {},
   "source": [
    "Эта библиотека обладает большим количества предобученных промптов, затюненых под разные задачи и именно этот сценарий мы с вами и рассмотрим - посмотрим на доступный инструментарий этой библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "11765940-5ec7-40a1-9b2c-a6c9d98aa61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ruprompts -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc95b4c-ff2d-4728-9413-55c1364368b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# although not used directly, this import is necessary,\n",
    "# since it adds custom pipelines to transformers\n",
    "import ruprompts\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d05e8cb-c21e-4323-8934-4d74da107ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sberbank-ai/rugpt3large_based_on_gpt2 and revision aa2b602 (https://huggingface.co/sberbank-ai/rugpt3large_based_on_gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "ppln_joke = pipeline(\"text-generation-with-prompt\", prompt=\"konodyuk/prompt_rugpt3large_joke\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d11679d-aa69-4633-8997-b12bcb4aa754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Говорит как-то дуб вороне. Стоит вороне, говорит дуб. А потом так хитро говорит дубу:- Ворона, я тебе обещал... Это слово в вороне и застряло.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppln_joke(\"Говорит как-то дуб вороне\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3076b6-9b7e-4086-9ac1-0b5f266d3f37",
   "metadata": {},
   "source": [
    "Конечно удобнее не указывать аргумент модели, однако это приводит к повторному созданию одной и той же модели каждый раз, когда мы создаем конвейер. Простое решение - создать модель и токенизатор один раз, а затем передавать их всем конвейерам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b667a2-c93b-49b3-a30f-1d15c76571d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "model_id = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28006526-a804-4717-8d58-c3d7905b09c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c1cf914826467ea280fb97d24ef8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt.json:   0%|          | 0.00/499 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628ee627281b49d09f79e6b5a2480f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt_provider.bin:   0%|          | 0.00/369k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Сколько ни спорь, а в ум войдешь.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppln_proverb = pipeline(\"text-generation-with-prompt\", prompt=\"konodyuk/prompt_rugpt3large_proverb\", model=model, tokenizer=tokenizer, device=0)\n",
    "ppln_proverb(\"Сколько ни\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d8e9f2f-01d7-4a74-9e93-732b6ca5f54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Учёные считают, что дикая кошка могла сама прийти к человеку, чтобы питаться грызунами'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = \"\"\"Несмотря на споры, большинство учёных сошлись во мнении, что кошка является полуодомашненным животным, то есть она способна на сосуществование с человеком, но, потеряв с ним контакт, легко возвращаются к дикому образу существования. Хотя у кошки наблюдаются генетические изменения в сравнении с диким предком, эта разница в 10 раз меньше, чем у собак с волками. Учёные считают, что дикая кошка действительно могла сама прийти к человеку, чтобы питаться грызунами, а такие отношения характеризовались как соседские, и уже через несколько тысяч лет люди сами стали одомашнивать маленьких хищников. Это также, вероятно, объясняет, почему модель поведения кошки почти не изменилась; при одомашнивании собаки из волка человек изменил её образ жизни и среду обитания, кошка же претерпела минимальные изменения Кошка сумела сохранить модель поведения, присущую её диким предкам. Она почти так же хорошо охотится, как дикая кошка, но в то же время способна мирно сосуществовать с человеком, проявлять к нему эмоциональную привязанность, нежность или даже выказывать игривое поведение.\"\"\"\n",
    "ppln_summary = pipeline(\"text2text-generation-with-prompt\", prompt=\"konodyuk/prompt_rugpt3large_summarization_mlsum\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "ppln_summary(long_text, num_beams=5, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0e2c6b2-a1bc-4742-84fc-7dfdb991766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba032fb2e5c43798b72ba036794a33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt.json:   0%|          | 0.00/837 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056e81deb5cb4dbe9b2e62117c2d113c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt_provider.bin:   0%|          | 0.00/738k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Попроси его зайти сюда'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppln_detox = pipeline(\"text2text-generation-with-prompt\", prompt=\"konodyuk/prompt_rugpt3large_detox_russe\", model=model, tokenizer=tokenizer, device=0)\n",
    "ppln_detox({\"toxic_comment\": \"Ублюдок, мать твою, а ну иди сюда\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91032985-45be-4665-81f7-d5ce72349dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac99dd5f29245f38fee3189414d4991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt.json:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe953355e3444dc2b980d3b25aa1c966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "prompt_provider.bin:   0%|          | 0.00/369k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Сепп Хохрайтер'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\"В 1997 году Шмидхубер и Сепп Хохрайтер опубликовали работу, описывающую рекуррентную нейронную сеть, которую авторы назвали «Долгая краткосрочная память». В 2015 году эта архитектура была использована в новой реализации распознавания речи в программном обеспечении компании Google для смартфонов.\n",
    "\n",
    "Исследования Шмидхубера также включают в себя генерализации колмогоровской сложности и метрики «скорость важна» (Speed Prior), создание концепции Машины Гёделя.\n",
    "\n",
    "В 2014 году Шмидхубер основал компанию Nnaisense для работы в сфере коммерческого применения технологий искусственного интеллекта в таких областях как финансы, тяжёлая промышленность и самоуправляемый автотранспорт. Сепп Хохрайтер и Яан Таллинн занимают в компании пост советников.\"\"\"\n",
    "\n",
    "ppln_qa = pipeline(\"text2text-generation-with-prompt\", prompt=\"konodyuk/prompt_rugpt3large_qa_sberquad\", model=model, tokenizer=tokenizer, device=0)\n",
    "ppln_qa({\"context\": context, \"question\": \"С кем Шмидхубер опубликовал работу?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96763973-ab5f-4158-9ff1-9e5c73de3f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
