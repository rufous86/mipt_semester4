{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35385544-cdab-4827-bb74-33ea1bcbb797",
   "metadata": {},
   "source": [
    "# Семинар 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ab232-366f-4179-a958-33852a01a9bf",
   "metadata": {},
   "source": [
    "В рамках данного задания мы расммотрим несколько возможных сценариев как можно использовать предобученную языковую модель и как модифицировать ее для улучшения ваших метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495589d2-23aa-4146-85f3-01b83ce68af4",
   "metadata": {},
   "source": [
    "Но для начала изучим частую используемую операцию и заметно сокращающую записи - это операцию EINSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0bf907e-ed99-4df8-a03d-6b42756dd813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da401fd-37e9-448b-a11f-a53557af7677",
   "metadata": {},
   "source": [
    "## Вводный блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084b1a2-0143-4e58-b132-d95229d0c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949b4dbd-c053-4de1-8bda-843b37727a10",
   "metadata": {},
   "source": [
    "## Тренировка модели BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361db7c0-39a7-47ef-b749-340a473c7ebd",
   "metadata": {},
   "source": [
    "Скачаем тренировочный датасет, для multilabel-классификации ненормативных комментариев на 4 класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191f448e-1dce-406c-a14e-532cbd54d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-09 00:15:02--  https://raw.githubusercontent.com/snv-ds/NLP_course/master/week2/train\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24525472 (23M) [text/plain]\n",
      "Saving to: ‘train’\n",
      "\n",
      "train               100%[===================>]  23,39M  39,9MB/s    in 0,6s    \n",
      "\n",
      "2024-02-09 00:15:04 (39,9 MB/s) - ‘train’ saved [24525472/24525472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/snv-ds/NLP_course/master/week2/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3058591-61c3-45ad-be2f-4631a03b0f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baselines\t      README.md\t\t\t       seminar_2.ipynb\n",
      "data\t\t      requirements.txt\t\t       seminar_6_solved.ipynb\n",
      "evaluation\t      ru_detoxification_evaluation.py  train\n",
      "__pycache__\t      ru_detoxification_metrics.py\n",
      "README_evaluation.md  seminar_1.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34653aa2-90d7-4dc5-97dc-fa3f894aae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_labels = ['__label__NORMAL','__label__INSULT','__label__THREAT','__label__OBSCENITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936d7055-3281-4d92-8a4f-b57795cb5877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>другое</th>\n",
       "      <th>оскорбление</th>\n",
       "      <th>непростойность</th>\n",
       "      <th>угроза</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117082</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>есть такое . есть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11298</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>теперь понятно почему рыба не клюёт, после так...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113653</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>стрелять стрелять и еще раз стрелять !!!! мы ж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140621</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>всем доброго вечера.. у нас сегодня дождь с жу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52572</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>всё верно говорит,таких людей много на украине...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243426</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>красавица и талантище- таких больше нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192888</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>музыка окутывает и укутывает в нежностью и таи...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        другое  оскорбление  непростойность  угроза  \\\n",
       "id                                                    \n",
       "117082       1            0               0       0   \n",
       "11298        0            1               0       1   \n",
       "113653       0            1               0       1   \n",
       "140621       1            0               0       0   \n",
       "52572        1            0               0       0   \n",
       "243426       1            0               0       0   \n",
       "192888       1            0               0       0   \n",
       "\n",
       "                                                  comment  \n",
       "id                                                         \n",
       "117082                                  есть такое . есть  \n",
       "11298   теперь понятно почему рыба не клюёт, после так...  \n",
       "113653  стрелять стрелять и еще раз стрелять !!!! мы ж...  \n",
       "140621  всем доброго вечера.. у нас сегодня дождь с жу...  \n",
       "52572   всё верно говорит,таких людей много на украине...  \n",
       "243426            красавица и талантище- таких больше нет  \n",
       "192888  музыка окутывает и укутывает в нежностью и таи...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train', sep='\\t', names=['id','target','temp1','temp2','comment'], index_col=0)\n",
    "\n",
    "mask = train['comment'].isin(parse_labels) # to cope only with correct rows in data\n",
    "\n",
    "train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask]['comment']\n",
    "train.loc[mask,'comment'] = np.nan\n",
    "\n",
    "for t in ['temp1','temp2']: # if comment have several labels of classes\n",
    "    mask = train[t].isin(parse_labels)\n",
    "    train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask][t]\n",
    "    train.loc[mask,t] = np.nan\n",
    "    train.loc[~train[t].isna(),'comment'] = train[~train[t].isna()][t]\n",
    "\n",
    "train[['оскорбление','другое','непростойность','угроза']] = train['target'].str.get_dummies(sep=',')\n",
    "\n",
    "train = train[['другое','оскорбление','непростойность','угроза', 'comment']]\n",
    "train.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26669eff-fab1-47fa-bfed-54760652539f",
   "metadata": {},
   "source": [
    "Ограничим датасет для ускорения тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d18f4b-170a-4a9d-a269-1687eb72ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(70000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb041383-083b-4cb7-81e0-808b6760e17f",
   "metadata": {},
   "source": [
    "## Использование BERT как feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53803e02-4f91-496d-b4d8-42935af00cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bb0ae2feb9474a9f99f8460266dbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b537ff7b934c3ca6d9ab803cc99e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce15627f02c4d038d1b1057f648e22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/241k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523ef6ded50a4ec5bda038af7e732689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/468k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3171a21d862148aba39853a5f722c091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dac02d7e86144b29b54a8e4f6f17df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/47.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 312)\n",
       "    (token_type_embeddings): Embedding(2, 312)\n",
       "    (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb4b74b-6620-41d8-b6c4-52fb91b68cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8216548c-256a-4852-ba12-8c44f13c1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(texts), 312))\n",
    "y = np.array(train[['другое',\t'оскорбление',\t'непростойность',\t'угроза']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33d83c9-4418-444b-ac30-770d7941ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt') # use padding, truncation of long sequences and return pytorch tensors\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()}) # move all tensors on the same device as model\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :] # use only first [CLS] token vector\n",
    "    embeddings = torch.nn.functional.normalize(embeddings) # normalize vector for easier convergence\n",
    "    return embeddings[0].cpu().numpy() # return result as numpy vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf8578f-8033-4273-89cd-f695b97b7f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ad4551bb5443c9be88edf26ff2754d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ind, sent in enumerate(tqdm(texts)):\n",
    "  x[ind] = embed_bert_cls(sent, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0edd5e73-a20c-45ae-a972-a59edc90faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c0d045e-e4b0-49ec-84ba-0678db2594ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2029)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f99a699c-f716-4dff-ab26-22679dbabf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 4), (52500, 312))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fca6e73c-ea7f-4e75-bbb6-9e844301fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37412c-4fb8-4bb1-b11d-cd9ad75295d6",
   "metadata": {},
   "source": [
    "Можете обучить любую модель классификации, которая вам по душе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ee66cc-b353-4bb0-a1a0-d7517e72466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = OneVsRestClassifier(estimator=LogisticRegression(random_state=2029, solver='sag', C=50)).fit(x_train, y_train)\n",
    "y_pred = simple_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dba14df-2ffd-439a-b5be-a77f29fd5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        другое       0.96      0.90      0.93     15287\n",
      "   оскорбление       0.45      0.70      0.55      1665\n",
      "непростойность       0.10      0.57      0.17        49\n",
      "        угроза       0.43      0.76      0.55       489\n",
      "\n",
      "     micro avg       0.85      0.87      0.86     17490\n",
      "     macro avg       0.48      0.73      0.55     17490\n",
      "  weighted avg       0.89      0.87      0.88     17490\n",
      "   samples avg       0.86      0.86      0.86     17490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test, target_names=['другое', 'оскорбление', 'непростойность', 'угроза'], zero_division=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fad04a-7005-4b5f-af41-134af462f220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48506d3-401a-4fd8-9640-beb86c20d8ab",
   "metadata": {},
   "source": [
    "## Используем BERT как эмбеддер "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b586d6a-6316-4195-97d0-42489be65a9a",
   "metadata": {},
   "source": [
    "Посчитаем общее количество параметров, которое есть в модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712722af-3a81-4c2b-a5c7-f138e9bf2917",
   "metadata": {},
   "source": [
    "В рамках каждой части мы будем инициализирвать датасет каждый раз, для возможности воспроизведения каждого блока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd40ef98-717b-4ba4-bc86-27f2a182514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "609d339e-0f49-4b3d-a26d-094a6ace72e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb4d2de9-32f2-4c93-8905-71c7cb865485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11784168"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b0df0e0-e492-4ce0-bc6c-3ed8a99fcd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>другое</th>\n",
       "      <th>оскорбление</th>\n",
       "      <th>непростойность</th>\n",
       "      <th>угроза</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68512</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>у вас доставка есть и фото можно личку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76623</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>получается у нас один диагноз подходит а по не...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       другое  оскорбление  непростойность  угроза  \\\n",
       "id                                                   \n",
       "68512       1            0               0       0   \n",
       "76623       1            0               0       0   \n",
       "\n",
       "                                                 comment  \n",
       "id                                                        \n",
       "68512             у вас доставка есть и фото можно личку  \n",
       "76623  получается у нас один диагноз подходит а по не...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train', sep='\\t', names=['id','target','temp1','temp2','comment'], index_col=0)\n",
    "\n",
    "mask = train['comment'].isin(parse_labels) # to cope only with correct rows in data\n",
    "\n",
    "train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask]['comment']\n",
    "train.loc[mask,'comment'] = np.nan\n",
    "\n",
    "for t in ['temp1','temp2']: # if comment have several labels of classes\n",
    "    mask = train[t].isin(parse_labels)\n",
    "    train.loc[mask,'target'] = train[mask]['target'] + ',' + train[mask][t]\n",
    "    train.loc[mask,t] = np.nan\n",
    "    train.loc[~train[t].isna(),'comment'] = train[~train[t].isna()][t]\n",
    "\n",
    "train[['оскорбление','другое','непростойность','угроза']] = train['target'].str.get_dummies(sep=',')\n",
    "\n",
    "train = train[['другое','оскорбление','непростойность','угроза', 'comment']]\n",
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f7edc90-4321-4755-83f4-785d8abfe2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(train.comment,\n",
    "                                                              train[['другое','оскорбление',\n",
    "                                                                     'непростойность','угроза']],\n",
    "                                                              test_size = 0.2,\n",
    "                                                              random_state=2029)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d495554-4014-477d-b55f-2dddd813f717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_text[:2].tolist()\n",
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True)\n",
    "# output\n",
    "sent_id.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af5a70-a188-4ea8-ad4e-af43c95b102d",
   "metadata": {},
   "source": [
    "Заметим, что  комментарии не такие длинные, поэтому в этом задании BERT может показать отличные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c05b92b7-0f32-4b0b-ab6a-289a3e8400a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d64f3b-fa43-405b-8b08-770720437e69",
   "metadata": {},
   "source": [
    "Посмотрим на высокий перцентиль, чтобы им ограничить наш сет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bac0fe1d-76c8-4732-83b2-28ede488b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(seq_len).quantile(0.965)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af71b32e-2e67-4351-8b83-d61fad068c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "train_text.tolist(),\n",
    "max_length = 50,\n",
    "padding='max_length',\n",
    "truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "val_text.tolist(),\n",
    "max_length = 50,\n",
    "padding='max_length',\n",
    "truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc55f81d-001a-4bdd-99d0-a4800020b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.values.tolist(), dtype=torch.float)\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.values.tolist(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48a6ff21-0c6c-44f3-9288-7705a15a1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data,\n",
    "                            sampler = val_sampler,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb953035-b4d4-4238-bb46-ba349e146e18",
   "metadata": {},
   "source": [
    "Попробуем заморозить все параметры параметры BERT`а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b62262f0-6b5d-4063-8613-ca09815fb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec032299-cd0b-4690-842b-35456ccbf65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, n_output):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "      self.relu =  nn.ReLU()\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(312, 128)\n",
    "\n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(128, n_output)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "      last_hidden_state = bert_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "      x = self.fc1(last_hidden_state)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "222ebe39-82c0-406d-85ba-9c7ec819de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_embeder = BERT_Arch(model, n_output=4).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88197b5b-11ae-46e8-b8a2-80e9528c9044",
   "metadata": {},
   "source": [
    "Пересчитаем количество обучаемых параметров в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad146a44-aca1-4dbc-a3dd-dffb352e5986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50cbbcf1-f9a4-49ae-8c07-7342d6c4d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model_embeder.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "348e75fb-7fac-4cdb-951d-2f5d1f0cb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c13a07af-6a3e-440d-918c-f6dc5dfd74ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7197, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = iter(train_dataloader).__next__()\n",
    "\n",
    "text, mask, label = batch\n",
    "pred = model_embeder(text.to(device), mask.to(device))\n",
    "\n",
    "cross_entropy(pred.cpu(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae1c36a9-b07b-4f3f-adfe-3f9ab981e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "  model.train()\n",
    "\n",
    "  total_loss = 0\n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return (avg_loss, total_preds), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6dfb4b15-aafb-4561-93f8-8ebe7b984895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss = 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds, total_labels = [], []\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(tqdm(val_dataloader)):\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      total_preds.append(preds.detach().cpu().numpy())\n",
    "      total_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "  total_labels  = np.concatenate(total_labels, axis=0)\n",
    "  \n",
    "  # print evaluation metrics for our model\n",
    "  print(classification_report(total_labels,\n",
    "                              torch.sigmoid(torch.tensor(total_preds)).round(),\n",
    "                              zero_division=True))\n",
    "\n",
    "  return (avg_loss, total_preds),  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21a5e346-e663-4bd1-8355-0441ef2b350e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce9b6c806c5410f83f608116ffeca6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acef02bb9ee645abb10ef34c27e33616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     24352\n",
      "           1       0.71      0.38      0.49      4458\n",
      "           2       0.82      0.04      0.07       470\n",
      "           3       0.76      0.40      0.52      1507\n",
      "\n",
      "   micro avg       0.87      0.83      0.85     30787\n",
      "   macro avg       0.79      0.44      0.50     30787\n",
      "weighted avg       0.86      0.83      0.83     30787\n",
      " samples avg       0.88      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.186\n",
      "\n",
      " Epoch 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c343eb44def34dc983d663cd4af2c3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1bf2d3cad94d4c85aebbae016a926f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     24352\n",
      "           1       0.71      0.38      0.49      4458\n",
      "           2       0.82      0.04      0.07       470\n",
      "           3       0.76      0.40      0.52      1507\n",
      "\n",
      "   micro avg       0.87      0.83      0.85     30787\n",
      "   macro avg       0.79      0.44      0.50     30787\n",
      "weighted avg       0.86      0.83      0.83     30787\n",
      " samples avg       0.88      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.186\n",
      "\n",
      " Epoch 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2488fc643dc74a28835c776e4b1095cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbf21fbe262459ea37150496362d495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     24352\n",
      "           1       0.71      0.38      0.49      4458\n",
      "           2       0.82      0.04      0.07       470\n",
      "           3       0.76      0.40      0.52      1507\n",
      "\n",
      "   micro avg       0.87      0.83      0.85     30787\n",
      "   macro avg       0.79      0.44      0.50     30787\n",
      "weighted avg       0.86      0.83      0.83     30787\n",
      " samples avg       0.88      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.186\n",
      "\n",
      " Epoch 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d73d37dd5a4bb2adeaefc16ebf9082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695a952ad0e54fed806d61fd4fb063c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     24352\n",
      "           1       0.71      0.38      0.49      4458\n",
      "           2       0.82      0.04      0.07       470\n",
      "           3       0.76      0.40      0.52      1507\n",
      "\n",
      "   micro avg       0.87      0.83      0.85     30787\n",
      "   macro avg       0.79      0.44      0.50     30787\n",
      "weighted avg       0.86      0.83      0.83     30787\n",
      " samples avg       0.88      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.186\n",
      "\n",
      " Epoch 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fe31024b104f678bd1e4042d8fa297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1245049ae3488890d77f357acfaa3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     24352\n",
      "           1       0.71      0.38      0.49      4458\n",
      "           2       0.82      0.04      0.07       470\n",
      "           3       0.76      0.40      0.52      1507\n",
      "\n",
      "   micro avg       0.87      0.83      0.85     30787\n",
      "   macro avg       0.79      0.44      0.50     30787\n",
      "weighted avg       0.86      0.83      0.83     30787\n",
      " samples avg       0.88      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.195\n",
      "Validation Loss: 0.186\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    (train_loss, _), model_embeder = train(model_embeder)\n",
    "    \n",
    "    #evaluate model\n",
    "    (valid_loss, _), model_embeder = evaluate(model_embeder)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_embeder.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e739a-779b-4cd8-8691-af46aa037a12",
   "metadata": {},
   "source": [
    "Попробуем более сложную архитектуру, использовав более продвинутый слой поверх BERT'а, например попробуйте GRU поверх BERT'а."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcfb1e4-ce7f-48a4-a837-b91f7caf0d3f",
   "metadata": {},
   "source": [
    "Не забывайте, что RNN работает с последовательностями и он ожидает вектор для каждого токена, которые были получены из эмбеддингов BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c79c845-c7de-49e1-ad1a-02dae3e34c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert, n_output):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "      self.rnn = nn.GRU(312,\n",
    "                        256,\n",
    "                        num_layers=2,\n",
    "                        batch_first=True,\n",
    "                        dropout=0.1)\n",
    "        \n",
    "      self.out = nn.Linear(256, n_output)\n",
    "        \n",
    "    #define the forward pass\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "      last_hidden_state = bert_output.last_hidden_state\n",
    "\n",
    "      _, hidden = self.rnn(last_hidden_state)\n",
    "        \n",
    "      #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "      hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "      #hidden = [batch size, hid dim]\n",
    "        \n",
    "      output = self.out(hidden)\n",
    "        \n",
    "      #output = [batch size, out dim]\n",
    "        \n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50de53a7-8579-478d-b06e-accbfce7f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = BERT_Arch(model, 4).to(device)\n",
    "optimizer = AdamW(model_gru.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42755d2-1548-4fa2-86de-bf2fdd50a0ae",
   "metadata": {},
   "source": [
    "Подсчитайте количество параметров, которое мы обучаем, и общее количество параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fbe8ca4-2881-4a35-b9c5-148598e0c62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6820, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = iter(train_dataloader).__next__()\n",
    "\n",
    "text, mask, label = batch\n",
    "pred = model_gru(text.to(device), mask.to(device))\n",
    "# pred\n",
    "cross_entropy(pred.cpu(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638290d9-ee40-49d7-99a8-8a484b9ef098",
   "metadata": {},
   "source": [
    "Обучая GRU можете заметить, что она обучается медленнее, но получим лучшее качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33708ea1-10bf-4821-a355-766f923ca79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df81df586e544ee8afdba5e87536efd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b583812e2c0847f0b7263771522444f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92     24352\n",
      "           1       0.64      0.40      0.50      4458\n",
      "           2       1.00      0.00      0.00       470\n",
      "           3       0.82      0.03      0.06      1507\n",
      "\n",
      "   micro avg       0.87      0.81      0.84     30787\n",
      "   macro avg       0.84      0.35      0.37     30787\n",
      "weighted avg       0.85      0.81      0.80     30787\n",
      " samples avg       0.87      0.83      0.83     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.313\n",
      "Validation Loss: 0.204\n",
      "\n",
      " Epoch 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ec77e739b743fea22213719efbc215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd18fe2433c34b7f85193d653a1e8c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93     24352\n",
      "           1       0.71      0.48      0.57      4458\n",
      "           2       0.50      0.00      0.00       470\n",
      "           3       0.67      0.38      0.48      1507\n",
      "\n",
      "   micro avg       0.88      0.84      0.86     30787\n",
      "   macro avg       0.69      0.45      0.50     30787\n",
      "weighted avg       0.86      0.84      0.84     30787\n",
      " samples avg       0.89      0.85      0.85     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.204\n",
      "Validation Loss: 0.184\n",
      "\n",
      " Epoch 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ced2da577514cc995cad1cf96fb315e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c4cd37c16740709cf8bb029bdb4740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     24352\n",
      "           1       0.66      0.62      0.64      4458\n",
      "           2       0.26      0.02      0.03       470\n",
      "           3       0.71      0.41      0.52      1507\n",
      "\n",
      "   micro avg       0.88      0.85      0.86     30787\n",
      "   macro avg       0.64      0.50      0.53     30787\n",
      "weighted avg       0.87      0.85      0.85     30787\n",
      " samples avg       0.89      0.86      0.86     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.190\n",
      "Validation Loss: 0.176\n",
      "\n",
      " Epoch 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1698468f514e0d890a41ef079c37cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3932e65e814b445d9ee876afe3564aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     24352\n",
      "           1       0.79      0.53      0.63      4458\n",
      "           2       0.33      0.01      0.02       470\n",
      "           3       0.73      0.46      0.56      1507\n",
      "\n",
      "   micro avg       0.89      0.87      0.88     30787\n",
      "   macro avg       0.69      0.49      0.54     30787\n",
      "weighted avg       0.88      0.87      0.86     30787\n",
      " samples avg       0.90      0.88      0.88     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.178\n",
      "Validation Loss: 0.162\n",
      "\n",
      " Epoch 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c3f75ade0748038bdf097c21ff389c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6a7119e0924cd0852b9d95c92f9dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94     24352\n",
      "           1       0.76      0.62      0.69      4458\n",
      "           2       0.36      0.03      0.05       470\n",
      "           3       0.72      0.51      0.60      1507\n",
      "\n",
      "   micro avg       0.90      0.87      0.89     30787\n",
      "   macro avg       0.69      0.53      0.57     30787\n",
      "weighted avg       0.89      0.87      0.88     30787\n",
      " samples avg       0.91      0.88      0.88     30787\n",
      "\n",
      "\n",
      "Training Loss: 0.168\n",
      "Validation Loss: 0.152\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    (train_loss, _), model_gru = train(model_gru)\n",
    "    \n",
    "    #evaluate model\n",
    "    (valid_loss, _), model_gru = evaluate(model_gru)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_gru.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc100eb2-d3e8-49e9-8be9-d8ae3e1bce1b",
   "metadata": {},
   "source": [
    "### Что можно улучшить самостоятельно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf2123-54a4-4905-9027-f8faf2138954",
   "metadata": {},
   "source": [
    "Вы можете добавить:\n",
    "\n",
    "1. предварительную обработку текста\n",
    "2. увеличение тренировочного корпуса\n",
    "3. попробуйте более продвинутые слои поверх BERT (будьте осторожны, не переобучиться на train)\n",
    "4. используйте ансамбль моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012352e-461e-4af2-8d40-97aff3ec4e42",
   "metadata": {},
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f5f19-32cf-4ee6-88b2-0fbaad7086cc",
   "metadata": {},
   "source": [
    "После изучения основных методов дообучения BERT, давайте рассмотрим как можно расширить контекст BERT-like модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4d00f-b253-4459-beff-4e3c5f52102a",
   "metadata": {},
   "source": [
    "Существует модель [LongFormer](https://arxiv.org/abs/2004.05150), которая достаточно эффективно решает задачу увеличения контекста модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d113f-1cac-418f-becd-14edd2a47ec5",
   "metadata": {},
   "source": [
    "В ней используется разделение внимания на локальное и глобальное, у каждого свои весовые матрицы. Для глобального self-attention выбирается фиксированный набор токенов (могут быть важные, типа CLS или токенов вопроса для QA), на эти токены могут смотреть все остальные токены, и эти токены могут взаимодействовать со всеми остальными.\n",
    "\n",
    "В локальном внимании токен может смотреть на N токенов вокруг себя, от слоя к слою захватывая всё более длинные зависимости. При этом N токенов могут быть как ближайшими к текущему обрабатываемому, так и идти с заданным шагом (Dilated Sliding Window, допустимо на верхних слоях). Разные головы self-attention могут иметь шаблоны внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f641f-8b4c-4be9-be0c-04ad54e7b8f9",
   "metadata": {},
   "source": [
    "![](./images/longformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b953fb-e92c-45b1-acd7-9e15be9814f7",
   "metadata": {},
   "source": [
    "Скорее всего вам никогда не придется дообучать модель для поддержки более длинного контекста, однако для понимая принципов будет не лишним разобрать как это можно сделать. Мы с вами рассмотрим часть ноутбука коллеги, который обучал модели ru-longformer-tiny-16384 и другие ее аналоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc73526-9735-4bbe-b2d0-7eded6833303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertForMaskedLM, BertTokenizerFast, LongformerConfig, LongformerForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7cb4e-05a5-43e2-a0b6-a5953bc15103",
   "metadata": {},
   "source": [
    "В качестве базовой модели автор брал модель RoBERTa обученную на русском языке. Описанные далее подход позволяет использовать проверенную архитектуру модели, расширяя ее возможности для обработки более длинных документов или последовательностей текста, что особенно полезно в таких задачах как классификация документов, QA и других задачах, требующих глубокого понимания контекста.\n",
    "\n",
    "Longformer создается из роберты и можно сделать версии base и large. Однако эти модели будут не очень применимы на практике в силу своего внушительного размера (large-версия занимала порядка 38Gb видеопамяти обучаясь на векторах в 4096 токенов длиной, обучение base в fp16 займет порядка 16Gb карточку).\n",
    "\n",
    "Вся реализация далее основывается на оригинальной [статье](https://arxiv.org/abs/2004.05150) и [ноутбуке](https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb) от коллег из allenai, проделавших нечто похожее для модели RoBERTa\n",
    "\n",
    "Настройка конфигурации Longformer:\n",
    "\n",
    "Класс LongformerConfig используется для создания новой конфигурации для модели Longformer. Эта конфигурация тесно повторяет архитектуру модели RoBERT, но включает в себя корректировки для специфических особенностей Longformer. Параметры, такие как vocab_size, hidden_size, num_hidden_layers, num_attention_heads, intermediate_size, attention_probs_dropout_prob, hidden_dropout_prob и initializer_range, копируются напрямую из конфигурации RoBERT, чтобы обеспечить соответствие базовой архитектуры Longformer архитектуре RoBERTa.\n",
    "max_position_embeddings=16386 явно устанавливается для определения максимальной длины последовательности, которую может обрабатывать Longformer. Это значительно больше, чем у стандартных моделей RoBERTa, позволяя Longformer обрабатывать гораздо более длинные последовательности.  \n",
    "\n",
    "Инициализация модели Longformer для MLM: LongformerForMaskedLM(longformer_config) инициализирует модель Longformer с указанной конфигурацией. Эта модель готова к задачам Masked Language Modeling, но специально разработана для обработки более длинных последовательностей, чем RoBERTa, что делает ее подходящей для приложений, требующих расширенного контекста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ed0fc-eb48-438f-9878-1e8f55c22e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = RobertaForMaskedLM.from_pretrained('ai-forever/ruRoberta-large')\n",
    "roberta_config = roberta_model.config\n",
    "longformer_config = LongformerConfig.from_pretrained(\n",
    "        \"allenai/longformer-large-4096\",\n",
    "        attention_window=512,\n",
    "        hidden_size=roberta_config.hidden_size,\n",
    "        num_hidden_layers=roberta_config.num_hidden_layers,\n",
    "        num_attention_heads=roberta_config.num_attention_heads,\n",
    "        intermediate_size=roberta_config.intermediate_size,\n",
    "        hidden_act=roberta_config.hidden_act,\n",
    "        hidden_dropout_prob=roberta_config.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=roberta_config.attention_probs_dropout_prob,\n",
    "        max_position_embeddings=4098,\n",
    "        type_vocab_size=roberta_config.type_vocab_size,\n",
    "        initializer_range=roberta_config.initializer_range,\n",
    "        layer_norm_eps=roberta_config.layer_norm_eps,\n",
    "        gradient_checkpointing=roberta_config.gradient_checkpointing,\n",
    "        pad_token_id=roberta_config.pad_token_id\n",
    "    )\n",
    "\n",
    "longformer_model = LongformerForMaskedLM(longformer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddbbc32-7643-41ad-9fdc-a114b0971d1f",
   "metadata": {},
   "source": [
    "Расширим позишн энкодинг роберты просто перекопировав обученный position_embedding на позиции выше 512 друг за другом - авторы оригинальной статьи утверждают, что это наиболее эффективный способ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edfeac-5378-4897-8267-a857467f8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = longformer_model.config\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"ai-forever/ruRoberta-large\", model_max_length=4096)\n",
    "tokenizer.model_max_length = config.max_position_embeddings-2\n",
    "tokenizer.init_kwargs['model_max_length'] = config.max_position_embeddings-2\n",
    "\n",
    "current_max_pos, embed_size = roberta_model.roberta.embeddings.position_embeddings.weight[:512,:].shape\n",
    "\n",
    "new_pos_embed = longformer_model.longformer.embeddings.position_embeddings.weight\n",
    "new_pos_embed.requires_grad=False\n",
    "\n",
    "k = 2\n",
    "step = current_max_pos\n",
    "\n",
    "while k < config.max_position_embeddings-1:\n",
    "    new_pos_embed[k:(k + step)] = roberta_model.roberta.embeddings.position_embeddings.weight[:512]\n",
    "    k += step\n",
    "    \n",
    "roberta_model.roberta.embeddings.position_embeddings.weight.data = new_pos_embed\n",
    "roberta_model.roberta.embeddings.position_ids.data = torch.tensor([i for i in range(config.max_position_embeddings)]).reshape(1, config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d2726-acd7-4125-9834-31936793aa33",
   "metadata": {},
   "source": [
    "Поместим обученные веса роберты в соответствующие слои в лонгформере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf384f12-3473-4362-ba61-32ab1b67e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "longformer_model.longformer.load_state_dict(roberta_model.roberta.state_dict(), strict=False)\n",
    "longformer_model.lm_head.load_state_dict(roberta_model.lm_head.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abd325-1098-4e2b-943e-3cdbd26a81d5",
   "metadata": {},
   "source": [
    "Переиспользуем веса attention (query, key, value) для инициализации глобального аттеншна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad0833-c88f-461f-9a02-dd771f2991c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "for i, (roberta_layer, longformer_layer) in enumerate(zip(roberta_model.roberta.encoder.layer, longformer_model.longformer.encoder.layer)):\n",
    "    longformer_layer.attention.self.query_global = copy.deepcopy(roberta_layer.attention.self.query)\n",
    "    longformer_layer.attention.self.key_global = copy.deepcopy(roberta_layer.attention.self.key)\n",
    "    longformer_layer.attention.self.value_global = copy.deepcopy(roberta_layer.attention.self.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51080621-7488-4c31-843a-f639ce4ad107",
   "metadata": {},
   "source": [
    "Далее остается только дообучить получившуюся модель на Masked Language Modeling задаче. Однако рассмотрим еще пару нюансов, которые также важны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee8f4a-3773-4ce5-bc5b-bdd78195b71a",
   "metadata": {},
   "source": [
    "Для файнтюнинга лонгформера вам потребуется датасет с длинными текстами, чтобы модель научилась извлекать информацию из расширенного контекста. Желательно дать модели пройти хотя бы 200М токенов.\n",
    "\n",
    "Можно попробовать заморозить все веса модели, кроме глобальных аттеншнов и позишн энкодинга, если считаете что веса предобученной модели и так оптимальны.\n",
    "\n",
    "Однако, для дообучения модели на MLM задаче необходимо написать кастомный DataCollator, в который добавляется глобал аттеншн, который объявляется для всех токенов [MASK]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e73f7-883f-4558-8b21-be3762e2efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorWithGlobalAttention(DataCollatorForLanguageModeling):\n",
    "    def __call__(self, examples):\n",
    "        batch = super().__call__(examples)\n",
    "        global_attention_mask = [\n",
    "            [1 if token_id == tokenizer.mask_token_id else 0 for token_id in input_ids]\n",
    "            for input_ids in batch[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "        global_attention_mask = [\n",
    "            mask if any(mask) else [1] + [0]*(len(mask)-1)\n",
    "            for mask in global_attention_mask\n",
    "        ]\n",
    "\n",
    "        batch[\"global_attention_mask\"] = torch.tensor(global_attention_mask)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d62f4-b7b9-40ec-8788-b053a48cde1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
