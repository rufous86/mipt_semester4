{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":68699,"databundleVersionId":7659021,"sourceType":"competition"},{"sourceId":165617723,"sourceType":"kernelVersion"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Семинар_5. Поиск оптимальных гиперпараметров модели. Optuna.","metadata":{}},{"cell_type":"markdown","source":"Цель семинара: освоить основные способы подбора гиперпараметров ml моделей\n\nПлан семинара:\n\n* Практика - попробуем gridsearch подход подбора гиперпараметров\n* Практика - запустим random search catboost\n* Практика - осуществим подбор гиперпараметров библиотекой optuna\n* Подведение итогов - проанализируем и обсудим результаты","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\n\nimport numpy as np\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\nimport pandas as pd\npd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:40:34.110929Z","iopub.execute_input":"2024-03-18T15:40:34.111827Z","iopub.status.idle":"2024-03-18T15:40:35.514252Z","shell.execute_reply.started":"2024-03-18T15:40:34.111787Z","shell.execute_reply":"2024-03-18T15:40:35.513282Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. Задача gridsearch sklearn (10 минут)","metadata":{}},{"cell_type":"markdown","source":"Как вы уже могли убедиться на предидущих семинарах: изменяя гиперпараметры мы изменяем зачения метрик на валидации.\n\nGridsearch - простой перебор всех возможных комбинаций из параметров.\n\nЕсли мы настроили один параметр, не меняя остальные - это не значит, что полученное значение параметра является абсолютно идеальным.","metadata":{}},{"cell_type":"markdown","source":"Для начала подготовим данные.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/seminar1/train_multiclass.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:40:41.325000Z","iopub.execute_input":"2024-03-18T15:40:41.325760Z","iopub.status.idle":"2024-03-18T15:40:41.570194Z","shell.execute_reply.started":"2024-03-18T15:40:41.325724Z","shell.execute_reply":"2024-03-18T15:40:41.569308Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n0   0        584        590     909972     909977            16            8   \n1   1        808        816     728350     728372           433           20   \n2   2         39        192    2212076    2212144         11388          705   \n3   3        781        789    3353146    3353173           210           16   \n4   4       1540       1560     618457     618502           521           72   \n\n   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n0            5               2274                    113   \n1           54              44478                     70   \n2          420            1311391                     29   \n3           29               3202                    114   \n4           67              48231                     82   \n\n   Maximum_of_Luminosity  Length_of_Conveyer  TypeOfSteel_A300  \\\n0                    140                1358                 0   \n1                    111                1687                 1   \n2                    141                1400                 0   \n3                    134                1387                 0   \n4                    111                1692                 0   \n\n   TypeOfSteel_A400  Steel_Plate_Thickness  Edges_Index  Empty_Index  \\\n0                 1                     50       0.7393       0.4000   \n1                 0                     80       0.7772       0.2878   \n2                 1                     40       0.0557       0.5282   \n3                 1                     40       0.7202       0.3333   \n4                 1                    300       0.1211       0.5347   \n\n   Square_Index  Outside_X_Index  Edges_X_Index  Edges_Y_Index  \\\n0        0.5000           0.0059         1.0000         1.0000   \n1        0.2581           0.0044         0.2500         1.0000   \n2        0.9895           0.1077         0.2363         0.3857   \n3        0.3333           0.0044         0.3750         0.9310   \n4        0.0842           0.0192         0.2105         0.9861   \n\n   Outside_Global_Index  LogOfAreas  Log_X_Index  Log_Y_Index  \\\n0                   0.0      1.2041       0.9031       0.6990   \n1                   1.0      2.6365       0.7782       1.7324   \n2                   0.0      4.0564       2.1790       2.2095   \n3                   1.0      2.3222       0.7782       1.4314   \n4                   1.0      2.7694       1.4150       1.8808   \n\n   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n0            -0.5000           -0.0104          0.1417       0          0   \n1             0.7419           -0.2997          0.9491       0          0   \n2            -0.0105           -0.0944          1.0000       0          0   \n3             0.6667           -0.0402          0.4025       0          0   \n4             0.9158           -0.2455          0.9998       0          0   \n\n   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  target  \n0         0       1          0      0             0       3  \n1         0       0          0      0             1       6  \n2         1       0          0      0             0       2  \n3         1       0          0      0             0       2  \n4         0       0          0      0             1       6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>X_Minimum</th>\n      <th>X_Maximum</th>\n      <th>Y_Minimum</th>\n      <th>Y_Maximum</th>\n      <th>Pixels_Areas</th>\n      <th>X_Perimeter</th>\n      <th>Y_Perimeter</th>\n      <th>Sum_of_Luminosity</th>\n      <th>Minimum_of_Luminosity</th>\n      <th>Maximum_of_Luminosity</th>\n      <th>Length_of_Conveyer</th>\n      <th>TypeOfSteel_A300</th>\n      <th>TypeOfSteel_A400</th>\n      <th>Steel_Plate_Thickness</th>\n      <th>Edges_Index</th>\n      <th>Empty_Index</th>\n      <th>Square_Index</th>\n      <th>Outside_X_Index</th>\n      <th>Edges_X_Index</th>\n      <th>Edges_Y_Index</th>\n      <th>Outside_Global_Index</th>\n      <th>LogOfAreas</th>\n      <th>Log_X_Index</th>\n      <th>Log_Y_Index</th>\n      <th>Orientation_Index</th>\n      <th>Luminosity_Index</th>\n      <th>SigmoidOfAreas</th>\n      <th>Pastry</th>\n      <th>Z_Scratch</th>\n      <th>K_Scatch</th>\n      <th>Stains</th>\n      <th>Dirtiness</th>\n      <th>Bumps</th>\n      <th>Other_Faults</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>584</td>\n      <td>590</td>\n      <td>909972</td>\n      <td>909977</td>\n      <td>16</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2274</td>\n      <td>113</td>\n      <td>140</td>\n      <td>1358</td>\n      <td>0</td>\n      <td>1</td>\n      <td>50</td>\n      <td>0.7393</td>\n      <td>0.4000</td>\n      <td>0.5000</td>\n      <td>0.0059</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>0.0</td>\n      <td>1.2041</td>\n      <td>0.9031</td>\n      <td>0.6990</td>\n      <td>-0.5000</td>\n      <td>-0.0104</td>\n      <td>0.1417</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>808</td>\n      <td>816</td>\n      <td>728350</td>\n      <td>728372</td>\n      <td>433</td>\n      <td>20</td>\n      <td>54</td>\n      <td>44478</td>\n      <td>70</td>\n      <td>111</td>\n      <td>1687</td>\n      <td>1</td>\n      <td>0</td>\n      <td>80</td>\n      <td>0.7772</td>\n      <td>0.2878</td>\n      <td>0.2581</td>\n      <td>0.0044</td>\n      <td>0.2500</td>\n      <td>1.0000</td>\n      <td>1.0</td>\n      <td>2.6365</td>\n      <td>0.7782</td>\n      <td>1.7324</td>\n      <td>0.7419</td>\n      <td>-0.2997</td>\n      <td>0.9491</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>39</td>\n      <td>192</td>\n      <td>2212076</td>\n      <td>2212144</td>\n      <td>11388</td>\n      <td>705</td>\n      <td>420</td>\n      <td>1311391</td>\n      <td>29</td>\n      <td>141</td>\n      <td>1400</td>\n      <td>0</td>\n      <td>1</td>\n      <td>40</td>\n      <td>0.0557</td>\n      <td>0.5282</td>\n      <td>0.9895</td>\n      <td>0.1077</td>\n      <td>0.2363</td>\n      <td>0.3857</td>\n      <td>0.0</td>\n      <td>4.0564</td>\n      <td>2.1790</td>\n      <td>2.2095</td>\n      <td>-0.0105</td>\n      <td>-0.0944</td>\n      <td>1.0000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>781</td>\n      <td>789</td>\n      <td>3353146</td>\n      <td>3353173</td>\n      <td>210</td>\n      <td>16</td>\n      <td>29</td>\n      <td>3202</td>\n      <td>114</td>\n      <td>134</td>\n      <td>1387</td>\n      <td>0</td>\n      <td>1</td>\n      <td>40</td>\n      <td>0.7202</td>\n      <td>0.3333</td>\n      <td>0.3333</td>\n      <td>0.0044</td>\n      <td>0.3750</td>\n      <td>0.9310</td>\n      <td>1.0</td>\n      <td>2.3222</td>\n      <td>0.7782</td>\n      <td>1.4314</td>\n      <td>0.6667</td>\n      <td>-0.0402</td>\n      <td>0.4025</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1540</td>\n      <td>1560</td>\n      <td>618457</td>\n      <td>618502</td>\n      <td>521</td>\n      <td>72</td>\n      <td>67</td>\n      <td>48231</td>\n      <td>82</td>\n      <td>111</td>\n      <td>1692</td>\n      <td>0</td>\n      <td>1</td>\n      <td>300</td>\n      <td>0.1211</td>\n      <td>0.5347</td>\n      <td>0.0842</td>\n      <td>0.0192</td>\n      <td>0.2105</td>\n      <td>0.9861</td>\n      <td>1.0</td>\n      <td>2.7694</td>\n      <td>1.4150</td>\n      <td>1.8808</td>\n      <td>0.9158</td>\n      <td>-0.2455</td>\n      <td>0.9998</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"targets = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n\nX = train.drop(columns=targets + ['target', 'id'])\ny = train['target']","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:40:45.624482Z","iopub.execute_input":"2024-03-18T15:40:45.625158Z","iopub.status.idle":"2024-03-18T15:40:45.635522Z","shell.execute_reply.started":"2024-03-18T15:40:45.625121Z","shell.execute_reply":"2024-03-18T15:40:45.634444Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n                                                  random_state=43, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:40:50.332046Z","iopub.execute_input":"2024-03-18T15:40:50.332425Z","iopub.status.idle":"2024-03-18T15:40:50.352386Z","shell.execute_reply.started":"2024-03-18T15:40:50.332380Z","shell.execute_reply":"2024-03-18T15:40:50.351410Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Сначала просто запустим xgboost","metadata":{}},{"cell_type":"code","source":"%%time\n\nparams = {\n    'objective': 'multi:softprob',\n    'tree_method': 'hist',\n    'seed': 42,\n    'num_class': 8,\n}\n\nxgb_model = XGBClassifier(**params)\n\nxgb_model.fit(X_train, y_train,\n              verbose=5)\n\ny_pred = xgb_model.predict_proba(X_test)\nroc_auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\nroc_auc","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:40:57.303205Z","iopub.execute_input":"2024-03-18T15:40:57.303882Z","iopub.status.idle":"2024-03-18T15:41:00.038884Z","shell.execute_reply.started":"2024-03-18T15:40:57.303850Z","shell.execute_reply":"2024-03-18T15:41:00.038048Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"CPU times: user 10.4 s, sys: 85.9 ms, total: 10.5 s\nWall time: 2.73 s\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0.8448449170043777"},"metadata":{}}]},{"cell_type":"markdown","source":"Теперь подберем параметры  с помощью gridsearch\n* Импортируйте нужный модуль из sklearn.model_selection\n* Задайте пространство возможных параметров (в [документации](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) посмотрите, как это нужно делать)\n* Проследите, чтобы отбор гиперпараметров происходил по подходящей для нас метрике\n* Запустите и выведите лучшие параметры и лучший скор\n* Для экономии времени не добавляйте слишком много параметров достаточно суммарно 3-4 экспериментов","metadata":{}},{"cell_type":"code","source":"%%time\n\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'objective': ['multi:softprob'],\n    'tree_method': ['hist'],\n    'seed': [42],\n    'num_class': [8],\n    'n_estimators': [80, 110],\n    'max_depth': [3, 6],\n}\n\nxgb_model = XGBClassifier()\n\ngrid_search = GridSearchCV(estimator=xgb_model,\n                           param_grid=param_grid,\n                           scoring='roc_auc_ovo',\n                           cv=3)\n\n#For integer/None inputs, if the estimator is a classifier and \n#y is either binary or multiclass, StratifiedKFold is used.\n\ngrid_search.fit(X_train, y_train,\n                verbose=20)\n\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:49:05.428590Z","iopub.execute_input":"2024-03-18T15:49:05.428998Z","iopub.status.idle":"2024-03-18T15:49:26.627402Z","shell.execute_reply.started":"2024-03-18T15:49:05.428968Z","shell.execute_reply":"2024-03-18T15:49:26.626725Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Best Parameters: {'max_depth': 3, 'n_estimators': 80, 'num_class': 8, 'objective': 'multi:softprob', 'seed': 42, 'tree_method': 'hist'}\nBest Score: 0.8588065761252519\nCPU times: user 1min 20s, sys: 486 ms, total: 1min 21s\nWall time: 21.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = grid_search.best_params_\n\nbest_xgb_model = XGBClassifier(**best_params)\n\nbest_xgb_model.fit(X_train, y_train,\n                    verbose=5)\n\ny_pred = best_xgb_model.predict_proba(X_test)\n\nroc_auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\nroc_auc","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:43:04.100608Z","iopub.execute_input":"2024-03-18T15:43:04.100993Z","iopub.status.idle":"2024-03-18T15:43:05.171578Z","shell.execute_reply.started":"2024-03-18T15:43:04.100964Z","shell.execute_reply":"2024-03-18T15:43:05.170658Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0.8593577604565884"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. random search (10 мин)","metadata":{}},{"cell_type":"markdown","source":"В отличие от GridSearchCV, не все значения параметров проверяются. Из указанных распределений проверяется фиксированное количество вариантов параметров.\n\nЕсли все параметры представлены в виде списка, выполняется выборка без замены. Если хотя бы один параметр задан как распределение, используется выборка с заменой. В документации рекомендуется использовать непрерывные распределения для непрерывных параметров.","metadata":{}},{"cell_type":"markdown","source":"* Запустите метод randomized_search из катбуста\n* Найдите в [документации](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier_randomized_search) каким параметром управляется кол-во экспериментов\n* Посмотрите как можно задавать гиперпараметры. Попробуйте задать как списком, так и распределением\n* Отключите логирование, чтобы не засорять ноутбук","metadata":{}},{"cell_type":"code","source":"from scipy.stats import randint\n\nmodel = CatBoostClassifier(task_type='GPU',\n                          logging_level='Silent',\n                           random_seed=42,\n                          )\n\ngrid = {'learning_rate': [0.03, 0.1],\n       # 'depth': [4, 8],\n       'depth': randint(3, 10),\n}\n\nrandomized_search_result = model.randomized_search(grid,\n                                                   cv=3,\n                                                   X=X_train, \n                                                   y=y_train,\n                                                   n_iter=3,\n                                                   plot=False)\n\nrandomized_search_result['params']","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:11:43.522001Z","iopub.execute_input":"2024-03-18T16:11:43.522333Z","iopub.status.idle":"2024-03-18T16:12:21.504812Z","shell.execute_reply.started":"2024-03-18T16:11:43.522308Z","shell.execute_reply":"2024-03-18T16:12:21.503869Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"0:\tloss: 1.0619740\tbest: 1.0619740 (0)\ttotal: 4.42s\tremaining: 8.85s\n1:\tloss: 1.0646326\tbest: 1.0619740 (0)\ttotal: 7.1s\tremaining: 3.55s\n2:\tloss: 1.0574348\tbest: 1.0574348 (2)\ttotal: 12.9s\tremaining: 0us\nEstimating final quality...\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'depth': 6.0, 'learning_rate': 0.03}"},"metadata":{}}]},{"cell_type":"markdown","source":"* Запустим тренировку с подобранными гиперпараметрами","metadata":{}},{"cell_type":"code","source":"best_params = randomized_search_result['params']\nmodel = CatBoostClassifier(task_type='GPU',random_seed=42, **best_params)\n\nmodel.fit(X_train, y_train, verbose=100)\n\ny_pred = model.predict_proba(X_test)\n\nroc_auc = roc_auc_score(y_test, y_pred, multi_class='ovo')\nroc_auc","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:00:22.704824Z","iopub.execute_input":"2024-03-18T16:00:22.705164Z","iopub.status.idle":"2024-03-18T16:00:28.780579Z","shell.execute_reply.started":"2024-03-18T16:00:22.705141Z","shell.execute_reply":"2024-03-18T16:00:28.779590Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"0:\tlearn: 2.0127939\ttotal: 6.74ms\tremaining: 6.73s\n100:\tlearn: 1.0779364\ttotal: 575ms\tremaining: 5.12s\n200:\tlearn: 1.0068419\ttotal: 1.14s\tremaining: 4.54s\n300:\tlearn: 0.9703119\ttotal: 1.72s\tremaining: 3.99s\n400:\tlearn: 0.9434083\ttotal: 2.3s\tremaining: 3.43s\n500:\tlearn: 0.9189095\ttotal: 2.86s\tremaining: 2.85s\n600:\tlearn: 0.8978186\ttotal: 3.44s\tremaining: 2.28s\n700:\tlearn: 0.8786987\ttotal: 4s\tremaining: 1.71s\n800:\tlearn: 0.8587561\ttotal: 4.63s\tremaining: 1.15s\n900:\tlearn: 0.8396941\ttotal: 5.2s\tremaining: 572ms\n999:\tlearn: 0.8218556\ttotal: 5.79s\tremaining: 0us\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.8606725186239743"},"metadata":{}}]},{"cell_type":"markdown","source":"Можно также использовать RandomizedSearchCV из sklearn","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint\n\nparam_distributions = {\n    'depth': randint(3, 10),\n    'l2_leaf_reg': uniform(0.1, 10),\n    'task_type': ['GPU'],\n}\n\ncatboost_model = CatBoostClassifier()\n\nrandom_search = RandomizedSearchCV(estimator=catboost_model, \n                                   param_distributions=param_distributions,\n                                   scoring='roc_auc_ovo',\n                                   cv=2, n_iter=3,\n                                   random_state=42)\n\n#random_search.fit(X_train, y_train, verbose = 10)\n\n#best_params = random_search.best_params_\n#best_score = random_search.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Optuna. Разминка  (10 мин)","metadata":{}},{"cell_type":"markdown","source":"* Библиотека с SoTA алгоритмами для подбора гиперпараметров\n* Есть ранняя остановка экспериметнтов (pruners)\n* Легко распараллеливается\n* Можно прикрутить dashboard с визуализацией обучения в реальном времени\n* Может быть интегрирован в большинство популярных ml библиотек (со списком можно ознакомиться в [документации](https://optuna.readthedocs.io/en/stable/reference/integration.html#optuna-integration) )","metadata":{}},{"cell_type":"markdown","source":"Для начала попробуем минимизировать функцию:\n* Нам нужно создать objective, который ссодержит пространство гипперпараметров и возвращает значение, которое нам нужно минимизировать.\n* Далее создаем study. И запускаем с нашим objective. Параметр n_trials контролирует кол-во экспериментов.","metadata":{}},{"cell_type":"code","source":"%%time\nimport optuna\n\ndef objective(trial):\n    x = trial.suggest_float('x', -10, 10)\n    return (x - 2) ** 2\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:07:13.113880Z","iopub.execute_input":"2024-03-18T16:07:13.114239Z","iopub.status.idle":"2024-03-18T16:07:14.161005Z","shell.execute_reply.started":"2024-03-18T16:07:13.114210Z","shell.execute_reply":"2024-03-18T16:07:14.160155Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"[I 2024-03-18 16:07:14,139] A new study created in memory with name: no-name-c11ae39a-b2c2-4002-bbcc-4ba94dc18832\n[I 2024-03-18 16:07:14,142] Trial 0 finished with value: 34.57644200582144 and parameters: {'x': -3.880173637387032}. Best is trial 0 with value: 34.57644200582144.\n[I 2024-03-18 16:07:14,143] Trial 1 finished with value: 51.26738565728312 and parameters: {'x': 9.160124695651824}. Best is trial 0 with value: 34.57644200582144.\n[I 2024-03-18 16:07:14,144] Trial 2 finished with value: 43.707242461660385 and parameters: {'x': -4.61114532147497}. Best is trial 0 with value: 34.57644200582144.\n[I 2024-03-18 16:07:14,146] Trial 3 finished with value: 31.451168767020555 and parameters: {'x': 7.608134160932721}. Best is trial 3 with value: 31.451168767020555.\n[I 2024-03-18 16:07:14,147] Trial 4 finished with value: 17.647404487804863 and parameters: {'x': -2.2008813941606187}. Best is trial 4 with value: 17.647404487804863.\n[I 2024-03-18 16:07:14,148] Trial 5 finished with value: 38.011584458917355 and parameters: {'x': -4.165353555062139}. Best is trial 4 with value: 17.647404487804863.\n[I 2024-03-18 16:07:14,149] Trial 6 finished with value: 50.82872480116825 and parameters: {'x': -5.129426681099137}. Best is trial 4 with value: 17.647404487804863.\n[I 2024-03-18 16:07:14,150] Trial 7 finished with value: 7.988166567616093 and parameters: {'x': -0.8263344755382533}. Best is trial 7 with value: 7.988166567616093.\n[I 2024-03-18 16:07:14,152] Trial 8 finished with value: 0.03380006331429808 and parameters: {'x': 2.183847935300612}. Best is trial 8 with value: 0.03380006331429808.\n[I 2024-03-18 16:07:14,153] Trial 9 finished with value: 1.709595430882125 and parameters: {'x': 0.6924850169569279}. Best is trial 8 with value: 0.03380006331429808.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 817 ms, sys: 50.7 ms, total: 867 ms\nWall time: 1.04 s\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'x': 2.183847935300612}"},"metadata":{}}]},{"cell_type":"markdown","source":"Результат не очень хороший. \n* Давайте попробуем получить результат получше - увеличьте кол-во экспериментов\n* Уберите логирование для каждого эксперимета, чтобы не засорять ноутбук (смотрим [доку](https://optuna.readthedocs.io/en/stable/reference/logging.html))\n","metadata":{}},{"cell_type":"code","source":"%%time\noptuna.logging.set_verbosity(optuna.logging.CRITICAL)\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=100)\n\nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:08:40.277448Z","iopub.execute_input":"2024-03-18T16:08:40.277849Z","iopub.status.idle":"2024-03-18T16:08:40.857661Z","shell.execute_reply.started":"2024-03-18T16:08:40.277817Z","shell.execute_reply":"2024-03-18T16:08:40.856726Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CPU times: user 572 ms, sys: 1.97 ms, total: 574 ms\nWall time: 573 ms\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'x': 2.0009728775266553}"},"metadata":{}}]},{"cell_type":"markdown","source":"* Представим, что нам нужно максимизировать функцию.\n* Поменяйте код, под задачу максимизации (область определения оставим неизменной (от -10 до 10)","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    x = trial.suggest_float('x', -10, 10)\n    return (x - 2) ** 2\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\n\nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:09:40.107560Z","iopub.execute_input":"2024-03-18T16:09:40.108253Z","iopub.status.idle":"2024-03-18T16:09:40.364846Z","shell.execute_reply.started":"2024-03-18T16:09:40.108220Z","shell.execute_reply":"2024-03-18T16:09:40.363943Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'x': -9.999301869533804}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 4. Optuna. Углубляемся (20 мин)","metadata":{}},{"cell_type":"markdown","source":"Байесовская оптимизация - итерационный метод, который на каждой итерации указывает наиболее вероятную точку, в которой наша целевая функция будет оптимальна. При этом выдаваемые вероятные точки включают две компоненты:\n\n* хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation) \n\n* хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration)","metadata":{}},{"cell_type":"markdown","source":"Основное отличие от gridsearch и randomsearch в том, что для выбора следующих экспериментов учитываются предыдущие.","metadata":{}},{"cell_type":"markdown","source":"Подберите [гиперпараметры](https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters) для XGBClassifier с помощью Optuna.\n\n**Обязательно добавьте по одному: целый, непрерывный и категориальный параметры**\n\nУчитывайте типы параметров:\n* suggest_categorical(name, choice) задает категориальные параметры. \n* suggest_float(name, low, high, *, step=None, log=False) задает параметр типа float - число с плавающей точкой.\n* suggest_int(name, low, high, step=1, log=False) задает параметр типа int - целое число. ","metadata":{}},{"cell_type":"code","source":"%%time\ndef objective(trial):\n    params = {\n        'objective': 'multi:softprob',\n        'tree_method': 'hist',\n        'seed': 42,\n        'num_class': 8,\n        'n_estimators': trial.suggest_categorical('n_estimators', [50, 90]),\n        'max_depth': trial.suggest_int('max_depth', 2, 7, step=1),\n        'boosting': trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n    }\n\n    xgb_model = XGBClassifier(**params)\n    xgb_model.fit(X_train, y_train,\n                  verbose=20)\n\n    y_pred = xgb_model.predict_proba(X_test)\n    score = roc_auc_score(y_test, y_pred, multi_class='ovo')\n    return score\n\nstudy = optuna.create_study(direction= 'maximize')\nstudy.optimize(objective, n_trials=10)\n\n\nbest_params = study.best_params\nbest_score = study.best_value\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:30:38.598192Z","iopub.execute_input":"2024-03-18T16:30:38.598921Z","iopub.status.idle":"2024-03-18T16:30:55.243005Z","shell.execute_reply.started":"2024-03-18T16:30:38.598888Z","shell.execute_reply":"2024-03-18T16:30:55.242019Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:38] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:39] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:40] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:45] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:47] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:49] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:50] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:51] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:52] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:30:54] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'n_estimators': 90, 'max_depth': 2, 'boosting': 'gbdt'}\nBest Score: 0.8622484839318804\nCPU times: user 1min 3s, sys: 260 ms, total: 1min 3s\nWall time: 16.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = study.best_params\n\nbest_xgb_model = XGBClassifier(**best_params)\nbest_xgb_model.fit(X_train, y_train)\n\ny_pred_proba = best_xgb_model.predict_proba(X_test)\n\nscore = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\nscore","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:24:38.182838Z","iopub.execute_input":"2024-03-18T16:24:38.183198Z","iopub.status.idle":"2024-03-18T16:24:39.110953Z","shell.execute_reply.started":"2024-03-18T16:24:38.183165Z","shell.execute_reply":"2024-03-18T16:24:39.110101Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:24:38] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.8622484839318804"},"metadata":{}}]},{"cell_type":"markdown","source":"## Sampler\nПосмотрите в [доке](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html) какой алгоритм используется оптюной по-умолчанию.\n* Попробуйте запустить подбор параметров с другим алгоритмом.\n* Подробнее про умную оптимизацию гиперпараметров можно почитать в [учебнике](https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov) от яндекс\n* Измерьте время работы алгоритма","metadata":{}},{"cell_type":"code","source":"%%time\ndef objective(trial):\n    params = {\n        'objective': 'multi:softprob',\n        'tree_method': 'hist',\n        'seed': 42,\n        'num_class': 8,\n        'n_estimators': trial.suggest_categorical('n_estimators', [50, 90]),\n        'max_depth': trial.suggest_int('max_depth', 2, 7, step=1),\n        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n    }\n\n    xgb_model = XGBClassifier(**params)\n    xgb_model.fit(X_train, y_train,\n                  verbose=20)\n\n    y_pred = xgb_model.predict_proba(X_test)\n    score = roc_auc_score(y_test, y_pred, multi_class='ovo')\n    return score\n\nstudy = optuna.create_study(sampler=optuna.samplers.CmaEsSampler(), \n                            direction='maximize'\n                           )\n\nstudy.optimize(objective, n_trials=15)\n\nbest_params = study.best_params\nbest_score = study.best_value\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:26:52.253006Z","iopub.execute_input":"2024-03-18T16:26:52.253367Z","iopub.status.idle":"2024-03-18T16:27:13.865454Z","shell.execute_reply.started":"2024-03-18T16:26:52.253338Z","shell.execute_reply":"2024-03-18T16:27:13.864454Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:52] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:53] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:54] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:55] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:56] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:57] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:26:59] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:02] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:03] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:05] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:06] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:07] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:09] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:11] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:27:13] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'n_estimators': 90, 'max_depth': 2, 'boosting_type': 'dart'}\nBest Score: 0.8622484839318804\nCPU times: user 1min 23s, sys: 350 ms, total: 1min 23s\nWall time: 21.6 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Pruner\nPruners в Optuna - это набор алгоритмов для прореживания экспериментов. Pruning - это механизм который позволяет обрывать эксперименты, которые с большой долей вероятности приведут к неоптимальным результатам.","metadata":{}},{"cell_type":"markdown","source":"* Добавте прунер в наш сетап\n* Сравните время работы с пруннингом и без пруннига","metadata":{}},{"cell_type":"code","source":"%%time\ndef objective(trial):\n    params = {\n        'objective': 'multi:softprob',\n        'tree_method': 'hist',\n        'seed': 42,\n        'num_class': 8,\n        'n_estimators': trial.suggest_categorical('n_estimators', [50, 90]),\n        'max_depth': trial.suggest_int('max_depth', 2, 7, step=1),\n        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n    }\n\n    xgb_model = XGBClassifier(**params)\n    xgb_model.fit(X_train, y_train,\n                  verbose=20)\n\n    y_pred = xgb_model.predict_proba(X_test)\n    score = roc_auc_score(y_test, y_pred, multi_class='ovo')\n    return score\n\n\nstudy = optuna.create_study(sampler=optuna.samplers.CmaEsSampler(),\n                            pruner=optuna.pruners.MedianPruner(),\n                            direction='maximize')\n\nstudy.optimize(objective, n_trials=15)\n\nbest_params = study.best_params\nbest_score = study.best_value\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:28:16.032642Z","iopub.execute_input":"2024-03-18T16:28:16.033481Z","iopub.status.idle":"2024-03-18T16:28:42.545737Z","shell.execute_reply.started":"2024-03-18T16:28:16.033450Z","shell.execute_reply":"2024-03-18T16:28:42.544735Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:16] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:17] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:18] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:19] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:20] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:20] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:22] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:22] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:25] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:27] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:28] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:30] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:33] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:36] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:28:40] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"boosting_type\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'n_estimators': 50, 'max_depth': 2, 'boosting_type': 'gbdt'}\nBest Score: 0.8612615380247617\nCPU times: user 1min 41s, sys: 399 ms, total: 1min 42s\nWall time: 26.5 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. Финальное задание. (20 мин)\n* Выберите параметры для catboost и py-boost, чтобы поставить ДОЛГИЙ эксперимент дома.\n* Оцените сколько примерно длится один эксперимент и поставте большое кол-во экспериментов, но чтобы влезть в лимиты kaggle\n* Сделайте инференс, с лучшими параметрами.\n* *Отправить сабмишн на ЛБ","metadata":{}},{"cell_type":"markdown","source":"### Catboost\n[Гиперпараметры](https://catboost.ai/en/docs/references/training-parameters/common)\n\nНапример,\n\n* iterations=,\n* learning_rate=,\n* l2_leaf_reg=,\n* depth=,","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'iterations' : 1400, # Можно не перебирать, есть Easrly-Stopping\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.01),\n        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 2, 50),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.8),\n\n        \"auto_class_weights\": trial.suggest_categorical(\"auto_class_weights\", [\"SqrtBalanced\", \"Balanced\", \"None\"]),\n        \"depth\": trial.suggest_int(\"depth\", 3, 9),\n\n        #\"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n        #\"used_ram_limit\": \"14gb\",\n        \"eval_metric\": \"Accuracy\", # Тоже стоит заранее определиться\n    }\n\n\n    if param[\"bootstrap_type\"] == \"Bayesian\":\n        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 20)\n\n    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n\n    catboost_model = CatBoostClassifier(task_type='GPU',random_seed=42, **params)\n    catboost_model.fit(X_train, y_train, verbose=20)\n\n    y_pred = catboost_model.predict_proba(X_test)\n    score = roc_auc_score(y_test, y_pred, multi_class='ovo')\n\n    return score\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=150)\n\nbest_params = study.best_params\nbest_score = study.best_value\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сохраните результаты","metadata":{}},{"cell_type":"code","source":"catboost_model = CatBoostClassifier(**best_params)\ncatboost_model.fit(X_train, y_train, verbose=20)\n\ny_pred = catboost_model.predict_proba(X_test)\nscore = roc_auc_score(y_test, y_pred, multi_class='ovo')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Py-boost","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns=targets + ['target', 'id'])\ny = train[targets]","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:42:45.818294Z","iopub.execute_input":"2024-03-18T16:42:45.818646Z","iopub.status.idle":"2024-03-18T16:42:45.825632Z","shell.execute_reply.started":"2024-03-18T16:42:45.818616Z","shell.execute_reply":"2024-03-18T16:42:45.824796Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n                                                  random_state=43)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:42:48.116235Z","iopub.execute_input":"2024-03-18T16:42:48.117052Z","iopub.status.idle":"2024-03-18T16:42:48.128622Z","shell.execute_reply.started":"2024-03-18T16:42:48.117016Z","shell.execute_reply":"2024-03-18T16:42:48.127756Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!pip install py-boost -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from py_boost import GradientBoosting\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:43:15.898964Z","iopub.execute_input":"2024-03-18T16:43:15.899397Z","iopub.status.idle":"2024-03-18T16:43:32.340320Z","shell.execute_reply.started":"2024-03-18T16:43:15.899365Z","shell.execute_reply":"2024-03-18T16:43:32.339491Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/cudf/utils/_numba.py:110: UserWarning: Using CUDA toolkit version (12, 3) with CUDA driver version (12, 2) requires minor version compatibility, which is not yet supported for CUDA driver versions 12.0 and above. It is likely that many cuDF operations will not work in this state. Please install CUDA toolkit version (12, 2) to continue using cuDF.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Посмотрим список возможных гиперпараметров\nmodel = GradientBoosting('bce')\nmodel.__dict__","metadata":{"execution":{"iopub.status.busy":"2024-03-18T16:43:45.737251Z","iopub.execute_input":"2024-03-18T16:43:45.738317Z","iopub.status.idle":"2024-03-18T16:43:45.746774Z","shell.execute_reply.started":"2024-03-18T16:43:45.738283Z","shell.execute_reply":"2024-03-18T16:43:45.745888Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'models': None,\n 'nfeats': None,\n 'postprocess_fn': <function py_boost.gpu.base.Ensemble._default_postprocess_fn(x)>,\n 'base_score': None,\n '_on_device': False,\n 'quantization': 'Quantile',\n 'quant_sample': 200000,\n 'max_bin': 256,\n 'min_data_in_bin': 3,\n 'seed': 42,\n 'params': {'loss': 'bce',\n  'metric': None,\n  'ntrees': 100,\n  'lr': 0.05,\n  'min_gain_to_split': 0,\n  'lambda_l2': 1,\n  'gd_steps': 1,\n  'max_depth': 6,\n  'min_data_in_leaf': 10,\n  'colsample': 1.0,\n  'subsample': 1.0,\n  'target_splitter': 'Single',\n  'multioutput_sketch': None,\n  'use_hess': True,\n  'quantization': 'Quantile',\n  'quant_sample': 2000000,\n  'max_bin': 256,\n  'min_data_in_bin': 3,\n  'es': 100,\n  'seed': 42,\n  'verbose': 10,\n  'callbacks': None,\n  'debug': False}}"},"metadata":{}}]},{"cell_type":"code","source":"def objective(trial):\n    \n    params = {'loss': 'bce',\n             ###}\n    model = GradientBoosting(**params)\n\n    model.fit(np.array(X_train), np.array(y_train))\n    \n    preds = model.predict(X_test)\n    score = roc_auc_score(y_test, preds, multi_class='ovo')\n    \n    return score\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=2)\n\nbest_params = study.best_params\nbest_score = study.best_value\n\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GradientBoosting(loss='bce', **best_params)\nmodel.fit(np.array(X_train), np.array(y_train))\n    \npreds = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}